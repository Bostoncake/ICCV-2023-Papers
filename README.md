# ICCV-2023-Papers

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
![Version](https://img.shields.io/badge/version-v0.0.0-rc0)
![GitHub repo size](https://img.shields.io/github/repo-size/DmitryRyumin/ICCV-2023-Papers)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/LICENSE)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/README.md)
![GitHub contributors](https://img.shields.io/github/contributors/dmitryryumin/ICCV-2023-Papers)
![GitHub commit activity (branch)](https://img.shields.io/github/commit-activity/t/dmitryryumin/ICCV-2023-Papers)
![GitHub closed issues](https://img.shields.io/github/issues-closed/DmitryRyumin/ICCV-2023-Papers)
![GitHub issues](https://img.shields.io/github/issues/DmitryRyumin/ICCV-2023-Papers)
![GitHub closed pull requests](https://img.shields.io/github/issues-pr-closed/DmitryRyumin/ICCV-2023-Papers)
![GitHub pull requests](https://img.shields.io/github/issues-pr/dmitryryumin/ICCV-2023-Papers)
![GitHub last commit](https://img.shields.io/github/last-commit/DmitryRyumin/ICCV-2023-Papers)
![GitHub watchers](https://img.shields.io/github/watchers/dmitryryumin/ICCV-2023-Papers)
![GitHub forks](https://img.shields.io/github/forks/dmitryryumin/ICCV-2023-Papers)
![GitHub Repo stars](https://img.shields.io/github/stars/dmitryryumin/ICCV-2023-Papers)
![Visitors](https://api.visitorbadge.io/api/combined?path=https%3A%2F%2Fgithub.com%2FDmitryRyumin%2FICCV-2023-Papers&label=Visitors&countColor=%23263759&style=flat)

> Completed: ![Progress](https://geps.dev/progress/26?successColor=006600)

---

ICCV 2023 Papers: Explore a comprehensive collection of cutting-edge research papers presented at [*ICCV 2023*](https://iccv2023.thecvf.com/), the premier computer vision conference. Keep up to date with the latest advances in computer vision and deep learning. Code implementations included. :star: the repository for the development of visual intelligence!

<p align="center">
    <a href="https://iccv2023.thecvf.com/" target="_blank">
        <img width="600" src="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/images/ICCV2023-banner.jpg" alt="ICCV 2023">
    </a>
<p>

---

[*The online version of the ICCV 2023 Conference Programme*](https://iccv2023.thecvf.com/main.conference.program-107.php), comprises a list of all accepted full papers, their presentation order, as well as the designated presentation times.

---

<a href="https://github.com/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arrow_click_cursor_pointer.png" width="25" />
  Other collections of the best AI conferences
</a>

<br />
<br />

> :exclamation: Conference table will be up to date all the time.

<table>
    <tr>
        <td><strong>Conference</strong></td>
        <td colspan="1" align="center"><strong>Year</strong></td>
    </tr>
    <tr>
      <td colspan="2" align="center"><i>Computer Vision (CV)</i></td>
    </tr>
    <tr>
        <td>CVPR</td>
        <td><a href="https://github.com/DmitryRyumin/CVPR-2023-Papers" target="_blank">2023</a></td>
    </tr>
    <tr>
      <td colspan="2" align="center"><i>Speech (SP)</i></td>
    </tr>
    <tr>
        <td>ICASSP</td>
        <td><a href="https://github.com/DmitryRyumin/ICASSP-2023-Papers" target="_blank">2023</a></td>
    </tr>
    <tr>
        <td>INTERSPEECH</td>
        <td><a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers" target="_blank">2023</a></td>
    </tr>
</table>

---

## Contributors

<a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/graphs/contributors">
  <img src="http://contributors.nn.ci/api?repo=DmitryRyumin/ICCV-2023-Papers" />
</a>

<br />
<br />

Contributions to improve the completeness of this list are greatly appreciated. If you come across any overlooked papers, please **feel free to [*create pull requests*](https://github.com/DmitryRyumin/ICCV-2023-Papers/pulls), [*open issues*](https://github.com/DmitryRyumin/ICCV-2023-Papers/issues) or contact me via [*email*](mailto:neweraairesearch@gmail.com)**. Your participation is crucial to making this repository even better.

---

## [Papers](https://iccv2023.thecvf.com/main.conference.program-107.php)

> :exclamation: Final paper links will be added post-conference.

<details open>
<summary>List of sections<a id="sections"></a></summary>

- [3D from Multi-View and Sensors](#3d-from-multi-view-and-sensors)
- [Adversarial Attack and Defense](#adversarial-attack-and-defense)
- [Vision and Robotics](#vision-and-robotics)
- [Vision and Graphics](#vision-and-graphics)
- [Segmentation, Grouping and Shape Analysis](#segmentation-grouping-and-shape-analysis)
- [Recognition: Categorization](#recognition-categorization)
- [Explainable AI for CV](#explainable-ai-for-cv)
- [Neural Generative Models](#neural-generative-models)
- [Vision and Language](#vision-and-language)
- [Vision, Graphics, and Robotics](#vision-graphics-and-robotics)
- [Privacy, Security, Fairness, and Explainability](#privacy-security-fairness-and-explainability)
- [Fairness, Privacy, Ethics, Social-good, Transparency, Accountability in Vision](#fairness-privacy-ethics-social-good-transparency-accountability-in-vision)
- [First Person (Egocentric) Vision](#first-person-egocentric-vision)
- [Representation Learning](#representation-learning)
- [Deep Learning Architectures](#deep-learning-architectures)
- [Recognition: Detection](#recognition-detection)
- [Image and Video Synthesis](#image-and-video-synthesis)
- [Vision and Audio](#vision-and-audio)
- [Recognition, Segmentation, and Shape Analysis](#recognition-segmentation-and-shape-analysis)
- [Generative AI](#generative-ai)
- [Humans, 3D Modeling, and Driving](#humans-3d-modeling-and-driving)
- [Low-Level Vision and Theory](#low-level-vision-and-theory)
- [Navigation and Autonomous Driving](#navigation-and-autonomous-driving)
- [3D from a Single Image and Shape-from-X](#3d-from-a-single-image-and-shape-from-x)
- [Motion Estimation, Matching and Tracking](#motion-estimation-matching-and-tracking)
- [Action and Event Understanding](#action-and-event-understanding)
- [Computational Imaging](#computational-imaging)
- [Embodied Vision: Active Agents; Simulation](#embodied-vision-active-agents-simulation)
- [Recognition: Retrieval](#recognition-retrieval)
- [Transfer, Low-Shot, Continual, Long-Tail Learning](#transfer-low-shot-continual-long-tail-learning)
- [Low-Level and Physics-based Vision](#low-level-and-physics-based-vision)
- [Computer Vision Theory](#computer-vision-theory)
- [Video Analysis and Understanding](#video-analysis-and-understanding)
- [Object Pose Estimation and Tracking](#object-pose-estimation-and-tracking)
- [3D Shape Modeling and Processing](#3d-shape-modeling-and-processing)
- [Human Pose/Shape Estimation](#human-poseshape-estimation)
- [Transfer, Low-Shot, and Continual Learning](#transfer-low-shot-and-continual-learning)
- [Self-, Semi-, and Unsupervised Learning](#self--semi--and-unsupervised-learning)
- [Self-, Semi-, Meta-, Unsupervised Learning](#self--semi--meta--unsupervised-learning)
- [Photogrammetry and Remote Sensing](#photogrammetry-and-remote-sensing)
- [Efficient and Scalable Vision](#efficient-and-scalable-vision)
- [Machine Learning (other than Deep Learning)](#machine-learning-other-than-deep-learning)
- [Document Analysis and Understanding](#document-analysis-and-understanding)
- [Biometrics](#biometrics)
- [Datasets and Evaluation](#datasets-and-evaluation)
- [Faces and Gestures](#faces-and-gestures)
- [Medical and Biological Vision; Cell Microscopy](#medical-and-biological-vision-cell-microscopy)
- [Scene Analysis and Understanding](#scene-analysis-and-understanding)
- [Multimodal Learning](#multimodal-learning)
- [Human-in-the-Loop Computer Vision](#human-in-the-loop-computer-vision)
- [Image and Video Forensics](#image-and-video-forensics)
- [Geometric Deep Learning](#geometric-deep-learning)
- [Vision Applications and Systems](#vision-applications-and-systems)
- [Machine Learning and Dataset](#machine-learning-and-dataset)

</details>

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### 3D from Multi-View and Sensors

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Multi-Modal Neural Radiance Field for Monocular Dense SLAM with a Light-Weight ToF Sensor | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.14383-b31b1b.svg)](https://arxiv.org/abs/2308.14383) | :heavy_minus_sign: |
| ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cy94.github.io/scannetpp/) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11417-b31b1b.svg)](https://arxiv.org/abs/2308.11417) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=E6P9e2r6M8I) |
| Translating Images to Road Network: A Non-Autoregressive Sequence-to-Sequence Approach | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Doppelgangers: Learning to Disambiguate Images of Similar Structures | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://doppelgangers-3d.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/RuojinCai/Doppelgangers)](https://github.com/RuojinCai/Doppelgangers) | :heavy_minus_sign: | :heavy_minus_sign: |
| EgoLoc: Revisiting 3D Object Localization from Egocentric Videos with Visual Queries | [![GitHub](https://img.shields.io/github/stars/Wayne-Mai/EgoLoc)](https://github.com/Wayne-Mai/EgoLoc) | [![arXiv](https://img.shields.io/badge/arXiv-2212.06969-b31b1b.svg)](https://arxiv.org/abs/2212.06969) | :heavy_minus_sign: |
| ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via an Indirect Recording Solution | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| EMR-MSF: Self-Supervised Recurrent Monocular Scene Flow Exploiting Ego-Motion Rigidity | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| ENVIDR: Implicit Differentiable Renderer with Neural Environment Lighting | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nexuslrf.github.io/ENVIDR/) <br /> [![GitHub](https://img.shields.io/github/stars/nexuslrf/ENVIDR)](https://github.com/nexuslrf/ENVIDR) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13022-b31b1b.svg)](https://arxiv.org/abs/2303.13022) | [![Google Drive](https://img.shields.io/badge/Google%20Drive-4285F4?style=for-the-badge&logo=googledrive&logoColor=white)](https://drive.google.com/file/d/18kU-IWVxboCG8SCGgrBA5JHC0JIgPCS8/view?t=17s) |
| Learning a more Continuous Zero Level Set in Unsigned Distance Fields through Level Set Projection | [![GitHub](https://img.shields.io/github/stars/junshengzhou/LevelSetUDF)](https://github.com/junshengzhou/LevelSetUDF) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11441-b31b1b.svg)](https://arxiv.org/abs/2308.11441) | :heavy_minus_sign: |
| GNT-MOVE: Generalizable NeRF Transformer with Mixture-of-View-Experts | [![GitHub](https://img.shields.io/github/stars/VITA-Group/GNT-MOVE)](https://github.com/VITA-Group/GNT-MOVE) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11793-b31b1b.svg)](https://arxiv.org/abs/2308.11793) | :heavy_minus_sign: |
| MatrixCity: A Large-Scale City Dataset for City-Scale Neural Rendering and Beyond | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://city-super.github.io/matrixcity/) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://city-super.github.io/matrixcity/img/matrixcity_camera_ready.pdf) | :heavy_minus_sign: |
| R3D3: Dense 3D Reconstruction of Dynamic Scenes from Multiple Cameras | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.vis.xyz/pub/r3d3/) <br /> [![GitHub](https://img.shields.io/github/stars/SysCV/r3d3)](https://github.com/SysCV/r3d3) | [![arXiv](https://img.shields.io/badge/arXiv-2308.14713-b31b1b.svg)](https://arxiv.org/abs/2308.14713) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lkU0lDq9HHw) |
| ClimateNeRF: Extreme Weather Synthesis in Neural Radiance Field | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://climatenerf.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2211.13226-b31b1b.svg)](https://arxiv.org/abs/2211.13226) | :heavy_minus_sign: |
| Rendering Humans from Object-Occluded Monocular Videos | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://cs.stanford.edu/~xtiange/projects/occnerf/) <br /> [![GitHub](https://img.shields.io/github/stars/tiangexiang/OccNeRF)](https://github.com/tiangexiang/OccNeRF) | [![arXiv](https://img.shields.io/badge/arXiv-2308.04622-b31b1b.svg)](https://arxiv.org/abs/2308.04622) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-LHyNdWGqTM) |
| AssetField: Assets Mining and Reconfiguration in Ground Feature Plane Representation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://city-super.github.io/assetfield/) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13953-b31b1b.svg)](https://arxiv.org/abs/2303.13953) | :heavy_minus_sign: |
| PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images | [![GitHub](https://img.shields.io/github/stars/megvii-research/PETR)](https://github.com/megvii-research/PETR) | [![arXiv](https://img.shields.io/badge/arXiv-2206.01256-b31b1b.svg)](https://arxiv.org/abs/2206.01256) | :heavy_minus_sign: |
| MIMO-NeRF: Fast Neural Rendering with Multi-Input Multi-Output Neural Radiance Fields | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Adaptive Positional Encoding for Bundle-Adjusting Neural Radiance Fields | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| NeuS2: Fast Learning of Neural Implicit Surfaces for Multi-View Reconstruction | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://vcai.mpi-inf.mpg.de/projects/NeuS2/) <br /> [![GitHub](https://img.shields.io/github/stars/19reborn/NeuS2)](https://github.com/19reborn/NeuS2) | [![arXiv](https://img.shields.io/badge/arXiv-2212.05231-b31b1b.svg)](https://arxiv.org/abs/2212.05231) | :heavy_minus_sign: |
| Learning from Semantic Alignment between Unpaired Multiviews for Egocentric Video Recognition | [![GitHub](https://img.shields.io/github/stars/wqtwjt1996/SUM-L)](https://github.com/wqtwjt1996/SUM-L) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11489-b31b1b.svg)](https://arxiv.org/abs/2308.11489) | :heavy_minus_sign: |
| Uncertainty Guided Adaptive Warping for Robust and Efficient Stereo Matching | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.14071-b31b1b.svg)](https://arxiv.org/abs/2307.14071) | :heavy_minus_sign: |
| Compatibility of Fundamental Matrices for Complete Viewing Graphs |  | [![arXiv](https://img.shields.io/badge/arXiv-2303.10658-b31b1b.svg)](https://arxiv.org/abs/2303.10658) | :heavy_minus_sign: |
| ProtoTransfer: Cross-Modal Prototype Transfer for Point Cloud Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| SA-BEV: Generating Semantic-Aware Bird's-Eye-View Feature for Multi-View 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/mengtan00/SA-BEV)](https://github.com/mengtan00/SA-BEV) | [![arXiv](https://img.shields.io/badge/arXiv-2307.11477-b31b1b.svg)](https://arxiv.org/abs/2307.11477) | :heavy_minus_sign: |
| GraphAlign: Enhancing Accurate Feature Alignment by Graph matching for Multi-Modal 3D Object Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Tangent Sampson Error: Fast Approximate Two-View Reprojection Error for Central Camera Models | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Using a Waffle Iron for Automotive Point Cloud Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/valeoai/WaffleIron)](https://github.com/valeoai/WaffleIron) | [![arXiv](https://img.shields.io/badge/arXiv-2301.10100-b31b1b.svg)](https://arxiv.org/abs/2301.10100) | :heavy_minus_sign: |
| Fast Globally Optimal Surface Normal Estimation from an Affine Correspondence | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| HeadsUp: A Data-Driven Volumetric Prior for Few-Shot Synthesis of Ultra High-Resolution Human Heads | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TILTED: Robust Neural Fields via Latent Registration | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Center-based Decoupled Point-Cloud Registration for 6D Object Pose Estimation | [![GitHub](https://img.shields.io/github/stars/Jiang-HB/CenterReg)](https://github.com/Jiang-HB/CenterReg) | :heavy_minus_sign: | :heavy_minus_sign: |
| Deep Geometry-Aware Camera Self-Calibration from Video | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| V-FUSE: Volumetric Depth Map Fusion with Long-Range Constraints | [![GitHub](https://img.shields.io/github/stars/nburgdorfer/V-FUSE)](https://github.com/nburgdorfer/V-FUSE) | [![arXiv](https://img.shields.io/badge/arXiv-2308.08715-b31b1b.svg)](https://arxiv.org/abs/2308.08715) | :heavy_minus_sign: |
| Consistent Depth Prediction for Transparent Object Reconstruction from RGB-D Camera | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| FaceCLIPNeRF: Text-Driven 3D Face Manipulation using Deformable Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://faceclipnerf.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2307.11418-b31b1b.svg)](https://arxiv.org/abs/2307.11418) | :heavy_minus_sign: |
| HollowNeRF: Pruning Hashgrid-based NeRFs with Trainable Collision Mitigation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.10122-b31b1b.svg)](https://arxiv.org/abs/2308.10122) | :heavy_minus_sign: |
| ICE-NeRF: Interactive Color Editing of NeRFs via Decomposition-Aware Weight Optimization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| FULLER: Unified Multi-Modality Multi-Task 3D Perception via Multi-Level Gradient Calibration |  | [![arXiv](https://img.shields.io/badge/arXiv-2307.16617-b31b1b.svg)](https://arxiv.org/abs/2307.16617) | :heavy_minus_sign: |
| Neural Fields for Structured Lighting | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| CO-Net: Learning Multiple Point Cloud Tasks at Once with a Cohesive Network | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Pose-Free Neural Radiance Fields via Implicit Pose Regularization | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.15049-b31b1b.svg)](https://arxiv.org/abs/2308.15049) | :heavy_minus_sign: |
| TransHuman: A Transformer-based Human Representation for Generalizable Neural Human Rendering | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://pansanity666.github.io/TransHuman/) <br /> [![GitHub](https://img.shields.io/github/stars/pansanity666/TransHuman)](https://github.com/pansanity666/TransHuman) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12291-b31b1b.svg)](https://arxiv.org/abs/2307.12291) | :heavy_minus_sign: |
| S-VolSDF: Sparse Multi-View Stereo Regularization of Neural Implicit Surfaces | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://hao-yu-wu.github.io/s-volsdf/) | [![arXiv](https://img.shields.io/badge/arXiv-2303.17712-b31b1b.svg)](https://arxiv.org/abs/2303.17712) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3_4PeVHWliY) |
| DPS-Net: Deep Polarimetric Stereo Depth Estimation | [![GitHub](https://img.shields.io/github/stars/Ethereal-Tian/DPS-Net)](https://github.com/Ethereal-Tian/DPS-Net) | :heavy_minus_sign: | :heavy_minus_sign: |
| 3DPPE: 3D Point Positional Encoding for Transformer-based Multi-Camera 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/drilistbox/3DPPE)](https://github.com/drilistbox/3DPPE) | [![arXiv](https://img.shields.io/badge/arXiv-2211.14710-b31b1b.svg)](https://arxiv.org/abs/2211.14710) | :heavy_minus_sign: |
| Deformable Neural Radiance Fields using RGB and Event Cameras | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Inter-Reflectable Light Fields for Geometry and Material Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yoyo000.github.io/NeILF_pp/) <br /> [![GitHub](https://img.shields.io/github/stars/apple/ml-neilfpp)](https://github.com/apple/ml-neilfpp) | [![arXiv](https://img.shields.io/badge/arXiv-2303.17147-b31b1b.svg)](https://arxiv.org/abs/2303.17147) | :heavy_minus_sign: |
| Hierarchical Prior Mining for Non-Local Multi-View Stereo | [![GitHub](https://img.shields.io/github/stars/CLinvx/HPM-MVS)](https://github.com/CLinvx/HPM-MVS) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09758-b31b1b.svg)](https://arxiv.org/abs/2303.09758) | :heavy_minus_sign: |
| Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/exiawsh/StreamPETR)](https://github.com/exiawsh/StreamPETR) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11926-b31b1b.svg)](https://arxiv.org/abs/2303.11926) | :heavy_minus_sign: |
| Re-ReND: Real-Time Rendering of NeRFs Across Devices | [![GitHub](https://img.shields.io/github/stars/sararoma95/Re-ReND)](https://github.com/sararoma95/Re-ReND) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08717-b31b1b.svg)](https://arxiv.org/abs/2303.08717) | :heavy_minus_sign: |
| Learning Shape Primitives via Implicit Convexity Regularization | [![GitHub](https://img.shields.io/github/stars/seanywang0408/ICR)](https://github.com/seanywang0408/ICR) | :heavy_minus_sign: | :heavy_minus_sign: |
| Geometry-Guided Feature Learning and Fusion for Indoor Scene Reconstruction | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment | [![GitHub](https://img.shields.io/github/stars/zhangzw12319/lcps)](https://github.com/zhangzw12319/lcps) | [![arXiv](https://img.shields.io/badge/arXiv-2308.01686-b31b1b.svg)](https://arxiv.org/abs/2308.01686) | :heavy_minus_sign: |
| PivotNet: End-to-End Learning for Vectorized HD Map Construction | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.16477-b31b1b.svg)](https://arxiv.org/abs/2308.16477) | :heavy_minus_sign: |
| Sat2Density: Faithful Density Learning from Satellite-Ground Image Pairs | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sat2density.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/qianmingduowan/Sat2Density)](https://github.com/qianmingduowan/Sat2Density) | [![arXiv](https://img.shields.io/badge/arXiv-2303.14672-b31b1b.svg)](https://arxiv.org/abs/2303.14672) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mf00PRXUpTU) |
| Mask-Attention-Free Transformer for 3D Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/dvlab-research/Mask-Attention-Free-Transformer)](https://github.com/dvlab-research/Mask-Attention-Free-Transformer) | [![arXiv](https://img.shields.io/badge/arXiv-2309.01692-b31b1b.svg)](https://arxiv.org/abs/2309.01692) | :heavy_minus_sign: |
| Scene-Aware Feature Matching | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.09949-b31b1b.svg)](https://arxiv.org/abs/2308.09949) | :heavy_minus_sign: |
| Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-Balanced Pseudo-Labeling | [![GitHub](https://img.shields.io/github/stars/zhuoxiao-chen/ReDB-DA-3Ddet)](https://github.com/zhuoxiao-chen/ReDB-DA-3Ddet) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07944-b31b1b.svg)](https://arxiv.org/abs/2307.07944) | :heavy_minus_sign: |
| GO-SLAM: Global Optimization for Consistent 3D Instant Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://youmi-zym.github.io/projects/GO-SLAM/) <br /> [![GitHub](https://img.shields.io/github/stars/youmi-zym/GO-SLAM)](https://github.com/youmi-zym/GO-SLAM) | [![arXiv](https://img.shields.io/badge/arXiv-2309.02436-b31b1b.svg)](https://arxiv.org/abs/2309.02436) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MbGn94Y4l8Y) |
| BANSAC: A Dynamic BAyesian Network for SAmple Consensus | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://pmiraldo.github.io/projects/bansac/bansac.html) | :heavy_minus_sign: | :heavy_minus_sign: |
| Theoretical and Numerical Analysis of 3D Reconstruction using Point and Line Incidences |  | [![arXiv](https://img.shields.io/badge/arXiv-2303.13593-b31b1b.svg)](https://arxiv.org/abs/2303.13593) | :heavy_minus_sign: |
| RealGraph: A Multiview Dataset for 4D Real-World Context Graph Generation | [![GitHub](https://img.shields.io/github/stars/THU-luvision/RealGraph)](https://github.com/THU-luvision/RealGraph) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://rqhuang88.github.io/html/RealGraph.html) | :heavy_minus_sign: |
| CL-MVSNet: Unsupervised Multi-View Stereo with Dual-Level Contrastive Learning | [![GitHub](https://img.shields.io/github/stars/KaiqiangXiong/CL-MVSNet)](https://github.com/KaiqiangXiong/CL-MVSNet) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://jianbojiao.com/pdfs/iccv23_clmvs.pdf) | :heavy_minus_sign: |
| Temporal Enhanced Training of Multi-View 3D Object Detector via Historical Object Prediction | [![GitHub](https://img.shields.io/github/stars/Sense-X/HoP)](https://github.com/Sense-X/HoP) | [![arXiv](https://img.shields.io/badge/arXiv-2304.00967-b31b1b.svg)](https://arxiv.org/abs/2304.00967) | :heavy_minus_sign: |
| Object as Query: Lifting any 2D Object Detector to 3D Detection | [![GitHub](https://img.shields.io/github/stars/tusen-ai/MV2D)](https://github.com/tusen-ai/MV2D) | [![arXiv](https://img.shields.io/badge/arXiv-2301.02364-b31b1b.svg)](https://arxiv.org/abs/2301.02364) | :heavy_minus_sign: |
| PARTNER: Level up the Polar Representation for LiDAR 3D Object Detection | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.03982-b31b1b.svg)](https://arxiv.org/abs/2308.03982) | :heavy_minus_sign: |
| Not Every Side is Equal: Localization Uncertainty Estimation for Semi-Supervised 3D Object Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Adversarial Attack and Defense

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Robust Mixture-of-Expert Training for Convolutional Neural Networks | [![GitHub](https://img.shields.io/github/stars/OPTML-Group/Robust-MoE-CNN)](https://github.com/OPTML-Group/Robust-MoE-CNN) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10110-b31b1b.svg)](https://arxiv.org/abs/2308.10110) | :heavy_minus_sign: |
| Set-Level Guidance Attack: Boosting Adversarial Transferability of Vision-Language Pre-Training Models | [![GitHub](https://img.shields.io/github/stars/Zoky-2020/SGA)](https://github.com/Zoky-2020/SGA) | [![arXiv](https://img.shields.io/badge/arXiv-2307.14061-b31b1b.svg)](https://arxiv.org/abs/2307.14061) | :heavy_minus_sign: |
| CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning | [![GitHub](https://img.shields.io/github/stars/nishadsinghi/CleanCLIP)](https://github.com/nishadsinghi/CleanCLIP) | [![arXiv](https://img.shields.io/badge/arXiv-2303.03323-b31b1b.svg)](https://arxiv.org/abs/2303.03323) | :heavy_minus_sign: |
| CGBA: Curvature-Aware Geometric Black-Box Attack | [![GitHub](https://img.shields.io/github/stars/Farhamdur/CGBA)](https://github.com/Farhamdur/CGBA) | [![arXiv](https://img.shields.io/badge/arXiv-2308.03163-b31b1b.svg)](https://arxiv.org/abs/2308.03163) | :heavy_minus_sign: |
| Robust Evaluation of Diffusion-based Adversarial Purification | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.09051-b31b1b.svg)](https://arxiv.org/abs/2303.09051) | :heavy_minus_sign: |
| Advancing Example Exploitation can Alleviate Critical Challenges in Adversarial Training | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| The Victim and the Beneficiary: Exploiting a Poisoned Model to Train a Clean Model on Poisoned Data | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal Backdoored Models | [![GitHub](https://img.shields.io/github/stars/SRI-CSL/TIJO)](https://github.com/SRI-CSL/TIJO) | [![arXiv](https://img.shields.io/badge/arXiv-2308.03906-b31b1b.svg)](https://arxiv.org/abs/2308.03906) | :heavy_minus_sign: |
| SAGA: Spectral Adversarial Geometric Attack on 3D Meshes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://stoliktomer.github.io/SAGA/) <br /> [![GitHub](https://img.shields.io/github/stars/StolikTomer/SAGA)](https://github.com/StolikTomer/SAGA) | [![arXiv](https://img.shields.io/badge/arXiv-2211.13775-b31b1b.svg)](https://arxiv.org/abs/2211.13775) | :heavy_minus_sign: |
| Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples | [![GitHub](https://img.shields.io/github/stars/qiufan319/benchmark_pc_attack)](https://github.com/qiufan319/benchmark_pc_attack) | [![arXiv](https://img.shields.io/badge/arXiv-2307.16361-b31b1b.svg)](https://arxiv.org/abs/2307.16361) | :heavy_minus_sign: |
| ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal and Robust Vehicle Evasion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://islab-ai.github.io/active-iccv2023/) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07009-b31b1b.svg)](https://arxiv.org/abs/2308.07009) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=m6m90kX0O3w) |
| Frequency-Aware GAN for Adversarial Manipulation Generation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Breaking Temporal Consistency: Generating Video Universal Adversarial Perturbations using Image Models | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Tracing the Origin of Adversarial Attack for Forensic Investigation and Deterrence | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2301.01218-b31b1b.svg)](https://arxiv.org/abs/2301.01218) | :heavy_minus_sign: |
| Downstream-Agnostic Adversarial Examples | [![GitHub](https://img.shields.io/github/stars/CGCL-codes/AdvEncoder)](https://github.com/CGCL-codes/AdvEncoder) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12280-b31b1b.svg)](https://arxiv.org/abs/2307.12280) | :heavy_minus_sign: |
| Hiding Visual Information via Obfuscating Adversarial Perturbations | [![GitHub](https://img.shields.io/github/stars/suzhigangssz/AVIH)](https://github.com/suzhigangssz/AVIH) | [![arXiv](https://img.shields.io/badge/arXiv-2209.15304-b31b1b.svg)](https://arxiv.org/abs/2209.15304) | :heavy_minus_sign: |
| An Embarrassingly Simple Self-Supervised Trojan Attack | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Efficient Decision-based Black-Box Patch Attacks on Video Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.11917-b31b1b.svg)](https://arxiv.org/abs/2303.11917) | :heavy_minus_sign: |
| Adversarial Finetuning with Latent Representation Constraint to Mitigate Accuracy-Robustness Tradeoff | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.16454-b31b1b.svg)](https://arxiv.org/abs/2308.16454) | :heavy_minus_sign: |
| Towards Building more Robust Models with Frequency Bias | [![GitHub](https://img.shields.io/github/stars/retsuh-bqw/ICCV23-Towards-Building-More-Robust-Models-with-Frequency-Bias)](https://github.com/retsuh-bqw/ICCV23-Towards-Building-More-Robust-Models-with-Frequency-Bias) | [![arXiv](https://img.shields.io/badge/arXiv-2307.09763-b31b1b.svg)](https://arxiv.org/abs/2307.09763) | :heavy_minus_sign: |
| System-Driven Adversarial Object Evasion Attack in Autonomous Driving | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/cav-sec/sysadv) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11894-b31b1b.svg)](https://arxiv.org/abs/2308.11894) | :heavy_minus_sign: |
| Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning | [![GitHub](https://img.shields.io/github/stars/microsoft/robustlearn)](https://github.com/microsoft/robustlearn) | [![arXiv](https://img.shields.io/badge/arXiv-2308.02533-b31b1b.svg)](https://arxiv.org/abs/2308.02533) | :heavy_minus_sign: |
| Enhancing Generalization of Universal Adversarial Perturbation through Gradient Aggregation | [![GitHub](https://img.shields.io/github/stars/liuxuannan/Stochastic-Gradient-Aggregation)](https://github.com/liuxuannan/Stochastic-Gradient-Aggregation) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06015-b31b1b.svg)](https://arxiv.org/abs/2308.06015) | :heavy_minus_sign: |
| Unified Adversarial Patch for Cross-Modal Attacks in the Physical World | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.07859-b31b1b.svg)](https://arxiv.org/abs/2307.07859) | :heavy_minus_sign: |
| RFLA: A Stealthy Reflected Light Adversarial Attack in the Physical World | [![GitHub](https://img.shields.io/github/stars/winterwindwang/RFLA)](https://github.com/winterwindwang/RFLA) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07653-b31b1b.svg)](https://arxiv.org/abs/2307.07653) | :heavy_minus_sign: |
| Enhancing Fine-Tuning based Backdoor Defense with Sharpness-Aware Minimization | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.11823-b31b1b.svg)](https://arxiv.org/abs/2304.11823) | :heavy_minus_sign: |
| Conditional 360-Degree Image Synthesis for Immersive Indoor Scene Decoration | [![GitHub](https://img.shields.io/github/stars/kcshum/neural_360_decoration)](https://github.com/kcshum/neural_360_decoration) | [![arXiv](https://img.shields.io/badge/arXiv-2307.09621-b31b1b.svg)](https://arxiv.org/abs/2307.09621) | :heavy_minus_sign: |
| An Adaptive Model Ensemble Adversarial Attack for Boosting Adversarial Transferability | [![GitHub](https://img.shields.io/github/stars/CHENBIN99/AdaEA)](https://github.com/CHENBIN99/AdaEA) | [![arXiv](https://img.shields.io/badge/arXiv-2308.02897-b31b1b.svg)](https://arxiv.org/abs/2308.02897) | :heavy_minus_sign: |
| Mitigating Adversarial Vulnerability through Causal Parameter Estimation by Adversarial Double Machine Learning | [![GitHub](https://img.shields.io/github/stars/ByungKwanLee/Double-Debiased-Adversary)](https://github.com/ByungKwanLee/Double-Debiased-Adversary) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07250-b31b1b.svg)](https://arxiv.org/abs/2307.07250) | :heavy_minus_sign: |
| LEA2: A Lightweight Ensemble Adversarial Attack via Non-Overlapping Vulnerable Frequency Regions | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Explaining Adversarial Robustness of Neural Networks from Clustering Effect Perspective | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| VertexSerum: Poisoning Graph Neural Networks for Link Inference | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.01469-b31b1b.svg)](https://arxiv.org/abs/2308.01469) | :heavy_minus_sign: |
| How to Choose Your Best Allies for a Transferable Attack? | [![GitHub](https://img.shields.io/github/stars/t-maho/transferability_measure_fit)](https://github.com/t-maho/transferability_measure_fit) | [![arXiv](https://img.shields.io/badge/arXiv-2304.02312-b31b1b.svg)](https://arxiv.org/abs/2304.02312) | :heavy_minus_sign: |
| Enhancing Adversarial Robustness in Low-Label Regime via Adaptively Weighted Regularization and Knowledge Distillation | [![GitHub](https://img.shields.io/github/stars/dyoony/SRST_AWR)](https://github.com/dyoony/SRST_AWR) | [![arXiv](https://img.shields.io/badge/arXiv-2308.04061-b31b1b.svg)](https://arxiv.org/abs/2308.04061) | :heavy_minus_sign: |
| AdvDiffuser: Natural Adversarial Example Synthesis with Diffusion Models | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| FnF Attack Adversarial Attack against Multiple Object Trackers by Inducing False Negatives and False Positives | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis | [![GitHub](https://img.shields.io/github/stars/LukasStruppek/Rickrolling-the-Artist)](https://github.com/LukasStruppek/Rickrolling-the-Artist) | [![arXiv](https://img.shields.io/badge/arXiv-2211.02408-b31b1b.svg)](https://arxiv.org/abs/2211.02408) | :heavy_minus_sign: |
| Hard No-Box Adversarial Attack on Skeleton-based Human Action Recognition with Skeleton-Motion-Informed Gradient | [![GitHub](https://img.shields.io/github/stars/luyg45/HardNoBoxAttack)](https://github.com/luyg45/HardNoBoxAttack) | [![arXiv](https://img.shields.io/badge/arXiv-2308.05681-b31b1b.svg)](https://arxiv.org/abs/2308.05681) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hvniybZIiqA) |
| Structure Invariant Transformation for Better Adversarial Transferability | [![GitHub](https://img.shields.io/github/stars/xiaosen-wang/SIT)](https://github.com/xiaosen-wang/SIT) | :heavy_minus_sign: | :heavy_minus_sign: |
| Beating Backdoor Attack at its Own Game | [![GitHub](https://img.shields.io/github/stars/damianliumin/non-adversarial_backdoor)](https://github.com/damianliumin/non-adversarial_backdoor) | [![arXiv](https://img.shields.io/badge/arXiv-2307.15539-b31b1b.svg)](https://arxiv.org/abs/2307.15539) | :heavy_minus_sign: |
| Transferable Adversarial Attack for Both Vision Transformers and Convolutional Networks via Momentum Integrated Gradients | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| REAP: A Large-Scale Realistic Adversarial Patch Benchmark | [![GitHub](https://img.shields.io/github/stars/wagner-group/reap-benchmark)](https://github.com/wagner-group/reap-benchmark) | [![arXiv](https://img.shields.io/badge/arXiv-2212.05680-b31b1b.svg)](https://arxiv.org/abs/2212.05680) | :heavy_minus_sign: |
| Multi-Metrics Adaptively Identifies Backdoors in Federated Learning | [![GitHub](https://img.shields.io/github/stars/siquanhuang/Multi-metrics_against_backdoors_in_FL)](https://github.com/siquanhuang/Multi-metrics_against_backdoors_in_FL) | [![arXiv](https://img.shields.io/badge/arXiv-2303.06601-b31b1b.svg)](https://arxiv.org/abs/2303.06601) | :heavy_minus_sign: |
| Backpropagation Path Search on Adversarial Transferability | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.07625-b31b1b.svg)](https://arxiv.org/abs/2308.07625) | :heavy_minus_sign: |
| Fast Adaptation of Neural Networks using Test-Time Feedback | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| One-Bit Flip is All You Need: When Bit-Flip Attack Meets Model Training | [![GitHub](https://img.shields.io/github/stars/jianshuod/TBA)](https://github.com/jianshuod/TBA) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07934-b31b1b.svg)](https://arxiv.org/abs/2308.07934) | :heavy_minus_sign: |
| PolicyCleanse: Backdoor Detection and Mitigation for Competitive Reinforcement Learning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2202.03609-b31b1b.svg)](https://arxiv.org/abs/2202.03609) | :heavy_minus_sign: |
| Towards Viewpoint-Invariant Visual Recognition via Adversarial Training | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.10235-b31b1b.svg)](https://arxiv.org/abs/2307.10235) | :heavy_minus_sign: |
| Fast Adversarial Training with Smooth Convergence | [![GitHub](https://img.shields.io/github/stars/FAT-CS/ConvergeSmooth)](https://github.com/FAT-CS/ConvergeSmooth) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12857-b31b1b.svg)](https://arxiv.org/abs/2308.12857) | :heavy_minus_sign: |
| The Perils of Learning from Unlabeled Data: Backdoor Attacks on Semi-Supervised Learning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2211.00453-b31b1b.svg)](https://arxiv.org/abs/2211.00453) | :heavy_minus_sign: |
| Boosting Adversarial Transferability via Gradient Relevance Attack | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Towards Robust Model Watermark via Reducing Parametric Vulnerability | [![GitHub](https://img.shields.io/github/stars/GuanhaoGan/robust-model-watermarking)](https://github.com/GuanhaoGan/robust-model-watermarking) | [![arXiv](https://img.shields.io/badge/arXiv-2309.04777-b31b1b.svg)](https://arxiv.org/abs/2309.04777) | :heavy_minus_sign: |
| TRM-UAP: Enhancing the Transferability of Data-Free Universal Adversarial Perturbation via Truncated Ratio Maximization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision and Robotics

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Simoun: Synergizing Interactive Motion-Appearance Understanding for Vision-based Reinforcement Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Among Us: Adversarially Robust Collaborative Perception by Consensus | [![GitHub](https://img.shields.io/github/stars/coperception/ROBOSAC)](https://github.com/coperception/ROBOSAC) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09495-b31b1b.svg)](https://arxiv.org/abs/2303.09495) | :heavy_minus_sign: |
| Walking Your LiDOG: A Journey Through Multiple Domains for LiDAR Semantic Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://saltoricristiano.github.io/lidog/) <br /> [![GitHub](https://img.shields.io/github/stars/saltoricristiano/LiDOG)](https://github.com/saltoricristiano/LiDOG) | [![arXiv](https://img.shields.io/badge/arXiv-2304.11705-b31b1b.svg)](https://arxiv.org/abs/2304.11705) | :heavy_minus_sign: |
| Stabilizing Visual Reinforcement Learning via Asymmetric Interactive Cooperation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MAAL: Multimodality-Aware Autoencoder-based Affordance Learning for 3D Articulated Objects | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Rethinking Range View Representation for LiDAR Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.05367-b31b1b.svg)](https://arxiv.org/abs/2303.05367) | :heavy_minus_sign: |
| PourIt!: Weakly-Supervised Liquid Perception from a Single Image for Visual Closed-Loop Robotic Pouring | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://hetolin.github.io/PourIt/) <br /> [![GitHub](https://img.shields.io/github/stars/hetolin/PourIt)](https://github.com/hetolin/PourIt) | [![arXiv](https://img.shields.io/badge/arXiv-2307.11299-b31b1b.svg)](https://arxiv.org/abs/2307.11299) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=R5SpiV0658Q) |
| CROSSFIRE: Camera Relocalization On Self-Supervised Features from an Implicit Representation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.04869-b31b1b.svg)](https://arxiv.org/abs/2303.04869) | :heavy_minus_sign: |
| Environment Agnostic Representation for Visual Reinforcement Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Test-Time Personalizable Forecasting of 3D Human Poses | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| HM-ViT: Hetero-Modal Vehicle-to-Vehicle Cooperative Perception with Vision Transformer | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.10628-b31b1b.svg)](https://arxiv.org/abs/2304.10628) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision and Graphics

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Efficient Neural Supersampling on a Novel Gaming Dataset | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.01483-b31b1b.svg)](https://arxiv.org/abs/2308.01483) | :heavy_minus_sign: |
| Locally Stylized Neural Radiance Fields | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| NEMTO: Neural Environment Matting for Novel View and Relighting Synthesis of Transparent Objects | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.11963-b31b1b.svg)](https://arxiv.org/abs/2303.11963) | :heavy_minus_sign: |
| DDColor: Towards Photo-Realistic and Semantic-Aware Image Colorization via Dual Decoders | [![GitHub](https://img.shields.io/github/stars/piddnad/DDColor)](https://github.com/piddnad/DDColor) <br /> [![ModelScope](https://img.shields.io/badge/ModelScope-DDColor-614BFF.svg)](https://www.modelscope.cn/models/damo/cv_ddcolor_image-colorization/summary) | [![arXiv](https://img.shields.io/badge/arXiv-2212.11613-b31b1b.svg)](https://arxiv.org/abs/2212.11613) | :heavy_minus_sign: |
| IntrinsicNeRF: Learning Intrinsic Neural Radiance Fields for Editable Novel View Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zju3dv.github.io/intrinsic_nerf/) <br /> [![GitHub](https://img.shields.io/github/stars/zju3dv/IntrinsicNeRF)](https://github.com/zju3dv/IntrinsicNeRF) | [![arXiv](https://img.shields.io/badge/arXiv-2210.00647-b31b1b.svg)](https://arxiv.org/abs/2210.00647) | :heavy_minus_sign: |
| PARIS: Part-Level Reconstruction and Motion Analysis for Articulated Objects | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://3dlg-hcvc.github.io/paris/) <br /> [![GitHub](https://img.shields.io/github/stars/3dlg-hcvc/paris)](https://github.com/3dlg-hcvc/paris) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07391-b31b1b.svg)](https://arxiv.org/abs/2308.07391) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tDSrROPCgUc) |
| ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mingyuan-zhang.github.io/projects/ReMoDiffuse.html) <br /> [![GitHub](https://img.shields.io/github/stars/mingyuan-zhang/ReMoDiffuse)](https://github.com/mingyuan-zhang/ReMoDiffuse) | [![arXiv](https://img.shields.io/badge/arXiv-2304.01116-b31b1b.svg)](https://arxiv.org/abs/2304.01116) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wSddrIA_2p8) |
| DS-Fusion: Artistic Typography via Discriminated and Stylized Diffusion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ds-fusion.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/tmaham/DS-Fusion)](https://github.com/tmaham/DS-Fusion) <br /> [![Hugging Face](https://img.shields.io/badge/🤗-tmaham-FFD21F.svg)](https://huggingface.co/spaces/tmaham/DS-Fusion-Express) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09604-b31b1b.svg)](https://arxiv.org/abs/2303.09604) | :heavy_minus_sign: |
| Dynamic Mesh-Aware Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mesh-aware-rf.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/YilingQiao/DMRF)](https://github.com/YilingQiao/DMRF) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://drive.google.com/file/d/1uXg76v0CNVxgrQfBHPR5SbxIMXyPLFfQ/view) | :heavy_minus_sign: |
| Neural Reconstruction of Relightable Human Model from Monocular Video | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Neural Microfacet Fields for Inverse Rendering | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://half-potato.gitlab.io/posts/nmf/) <br /> [![GitHub](https://img.shields.io/github/stars/half-potato/nmf)](https://github.com/half-potato/nmf) | [![arXiv](https://img.shields.io/badge/arXiv-2303.17806-b31b1b.svg)](https://arxiv.org/abs/2303.17806) | :heavy_minus_sign: |
| A Theory of Topological Derivatives for Inverse Rendering of Geometry | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ishit.github.io/td/) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09865-b31b1b.svg)](https://arxiv.org/abs/2308.09865) | :heavy_minus_sign: |
| Vox-E: Text-Guided Voxel Editing of 3D Objects | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tau-vailab.github.io/Vox-E/) <br /> [![GitHub](https://img.shields.io/github/stars/TAU-VAILab/Vox-E)](https://github.com/TAU-VAILab/Vox-E) | [![arXiv](https://img.shields.io/badge/arXiv-2303.12048-b31b1b.svg)](https://arxiv.org/abs/2303.12048) | :heavy_minus_sign: |
| StegaNeRF: Embedding Invisible Information within Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xggnet.github.io/StegaNeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/XGGNet/StegaNeRF)](https://github.com/XGGNet/StegaNeRF) | [![arXiv](https://img.shields.io/badge/arXiv-2212.01602-b31b1b.svg)](https://arxiv.org/abs/2212.01602) | :heavy_minus_sign: |
| GlobalMapper: Arbitrary-Shaped Urban Layout Generation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.09693-b31b1b.svg)](https://arxiv.org/abs/2307.09693) | :heavy_minus_sign: |
| Urban Radiance Field Representation with Deformable Neural Mesh Primitives | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dnmp.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/DNMP/DNMP)](https://github.com/DNMP/DNMP) | [![arXiv](https://img.shields.io/badge/arXiv-2307.10776-b31b1b.svg)](https://arxiv.org/abs/2307.10776) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JABhlaVq4VA) |
| End2End Multi-View Feature Matching with Differentiable Pose Optimization | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://barbararoessle.github.io/e2e_multi_view_matching/) | [![arXiv](https://img.shields.io/badge/arXiv-2205.01694-b31b1b.svg)](https://arxiv.org/abs/2205.01694) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5bFIIDOHRZY) |
| Tree-Structured Shading Decomposition | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chen-geng.com/inv-shade-trees/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/gcgeng/inv-shade-trees)](https://github.com/gcgeng/inv-shade-trees) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://chen-geng.com/files/inv-shade-trees.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=L7zD9zM_zcg) |
| Lens Parameter Estimation for Realistic Depth of Field Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lvsn.github.io/inversedof/) | :heavy_minus_sign: | :heavy_minus_sign: |
| AttT2M: Text-Driven Human Motion Generation with Multi-Perspective Attention Mechanism | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Cross-Modal Latent Space Alignment for Image to Avatar Translation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Computationally Efficient Neural Image Compression with Shallow Decoders | [![GitHub](https://img.shields.io/github/stars/mandt-lab/shallow-ntc)](https://github.com/mandt-lab/shallow-ntc) | [![arXiv](https://img.shields.io/badge/arXiv-2304.06244-b31b1b.svg)](https://arxiv.org/abs/2304.06244) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Segmentation, Grouping and Shape Analysis

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Enhancing Spatial and Semantic Supervision for Hybrid-based 3D Instance Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Learning Neural Eigenfunctions for Unsupervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/thudzj/NeuralEigenfunctionSegmentor)](https://github.com/thudzj/NeuralEigenfunctionSegmentor) | [![arXiv](https://img.shields.io/badge/arXiv-2304.02841-b31b1b.svg)](https://arxiv.org/abs/2304.02841) | :heavy_minus_sign: |
| Divide and Conquer: 3D Point Cloud Instance Segmentation with Point-Wise Binarization | [![GitHub](https://img.shields.io/github/stars/weiguangzhao/PBNet)](https://github.com/weiguangzhao/PBNet) | [![arXiv](https://img.shields.io/badge/arXiv-2207.11209-b31b1b.svg)](https://arxiv.org/abs/2207.11209) | :heavy_minus_sign: |
| Point2Mask: Point-Supervised Panoptic Segmentation via Optimal Transport | [![GitHub](https://img.shields.io/github/stars/LiWentomng/Point2Mask)](https://github.com/LiWentomng/Point2Mask) | [![arXiv](https://img.shields.io/badge/arXiv-2308.01779-b31b1b.svg)](https://arxiv.org/abs/2308.01779) | :heavy_minus_sign: |
| Handwritten and Printed Text Segmentation: A Signature Case Study | [![SignaTR6K](https://img.shields.io/badge/SignaTR6K-dataset-20BEFF.svg)](https://forms.office.com/r/2a5RDg7cAY) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07887-b31b1b.svg)](https://arxiv.org/abs/2307.07887) | :heavy_minus_sign: |
| Semantic-Aware Template Learning via Part Deformation Consistency | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.11916-b31b1b.svg)](https://arxiv.org/abs/2308.11916) | :heavy_minus_sign: |
| LeaF: Learning Frames for 4D Point Cloud Sequence Understanding | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MARS: Model-Agnostic Biased Object Removal without Additional Supervision for Weakly-Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/shjo-april/MARS)](https://github.com/shjo-april/MARS) | [![arXiv](https://img.shields.io/badge/arXiv-2304.09913-b31b1b.svg)](https://arxiv.org/abs/2304.09913) | :heavy_minus_sign: |
| USAGE: A Unified Seed Area Generation Paradigm for Weakly Supervised Semantic Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.07806-b31b1b.svg)](https://arxiv.org/abs/2303.07806) | :heavy_minus_sign: |
| Production-Level Video Segmentation from Few Annotated Frames | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://max810.github.io/xmem2-project-page/) <br /> [![GitHub](https://img.shields.io/github/stars/max810/XMem2)](https://github.com/max810/XMem2) | [![arXiv](https://img.shields.io/badge/arXiv-2307.15958-b31b1b.svg)](https://arxiv.org/abs/2307.15958) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3X3TUP4vKcc) |
| ΣIGMA: Scale-Invariant Global Sparse Shape Matching | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.08393-b31b1b.svg)](https://arxiv.org/abs/2308.08393) | :heavy_minus_sign: |
| Self-Calibrated Cross Attention Network for Few-Shot Segmentation | [![GitHub](https://img.shields.io/github/stars/Sam1224/SCCAN)](https://github.com/Sam1224/SCCAN) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09294-b31b1b.svg)](https://arxiv.org/abs/2308.09294) | :heavy_minus_sign: |
| Multi-Granularity Interaction Simulation for Unsupervised Interactive Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.13399-b31b1b.svg)](https://arxiv.org/abs/2303.13399) | :heavy_minus_sign: |
| Texture Learning Domain Randomization for Domain Generalized Segmentation | [![GitHub](https://img.shields.io/github/stars/ssssshwan/TLDR)](https://github.com/ssssshwan/TLDR) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11546-b31b1b.svg)](https://arxiv.org/abs/2303.11546) | :heavy_minus_sign: |
| Unsupervised Video Object Segmentation with Online Adversarial Self-Tuning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Exploring Open-Vocabulary Semantic Segmentation without Human Labels | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.00450-b31b1b.svg)](https://arxiv.org/abs/2306.00450) | :heavy_minus_sign: |
| RbA: Segmenting Unknown Regions Rejected by All | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kuis-ai.github.io/RbA/) <br /> [![GitHub](https://img.shields.io/github/stars/NazirNayal8/RbA)](https://github.com/NazirNayal8/RbA) | [![arXiv](https://img.shields.io/badge/arXiv-2211.14293-b31b1b.svg)](https://arxiv.org/abs/2211.14293) | :heavy_minus_sign: |
| SEMPART: Self-Supervised Multi-Resolution Partitioning of Image Semantics | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Multi-Object Discovery by Low-Dimensional Object Motion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kuis-ai.github.io/multi-object-segmentation/) <br /> [![GitHub](https://img.shields.io/github/stars/sadrasafa/multi-object-segmentation)](https://github.com/sadrasafa/multi-object-segmentation) | [![arXiv](https://img.shields.io/badge/arXiv-2307.08027-b31b1b.svg)](https://arxiv.org/abs/2307.08027) | :heavy_minus_sign: |
| MemorySeg: Online LiDAR Semantic Segmentation with a Latent Memory | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Treating Pseudo-Labels Generation as Image Matting for Weakly Supervised Semantic Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| BoxSnake: Polygonal Instance Segmentation with Box Supervision | [![GitHub](https://img.shields.io/github/stars/Yangr116/BoxSnake)](https://github.com/Yangr116/BoxSnake) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11630-b31b1b.svg)](https://arxiv.org/abs/2303.11630) | :heavy_minus_sign: |
| Dynamic Token Pruning in Plain Vision Transformers for Semantic Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.01045-b31b1b.svg)](https://arxiv.org/abs/2308.01045) | :heavy_minus_sign: |
| Instance Neural Radiance Field | [![GitHub](https://img.shields.io/github/stars/lyclyc52/Instance_NeRF)](https://github.com/lyclyc52/Instance_NeRF) | [![arXiv](https://img.shields.io/badge/arXiv-2304.04395-b31b1b.svg)](https://arxiv.org/abs/2304.04395) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wW9Bme73coI) |
| Global Knowledge Calibration for Fast Open-Vocabulary Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.09181-b31b1b.svg)](https://arxiv.org/abs/2303.09181) | :heavy_minus_sign: |
| Diffusion-based Image Translation with Label Guidance for Domain Adaptive Semantic Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.12350-b31b1b.svg)](https://arxiv.org/abs/2308.12350) | :heavy_minus_sign: |
| Boosting Semantic Segmentation from an Explicit Class Embedding's Perspective | [![gitee](https://gitee-badge.vercel.app/svg/stars/mindspore/models)](https://gitee.com/mindspore/models) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12894-b31b1b.svg)](https://arxiv.org/abs/2308.12894) | :heavy_minus_sign: |
| The Making and Breaking of Camouflage | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| CoinSeg: Contrast Inter- and Intra- Class Representations for Incremental Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Few-Shot Physically-Aware Articulated Mesh Generation via Hierarchical Deformation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://meowuu7.github.io/few-arti-obj-gen/) <br /> [![GitHub](https://img.shields.io/github/stars/Meowuu7/few-arti-gen)](https://github.com/Meowuu7/few-arti-gen) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10898-b31b1b.svg)](https://arxiv.org/abs/2308.10898) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=p8x3GN3VSPE) |
| HAL3D: Hierarchical Active Learning for Fine-Grained 3D Part Labeling | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2301.10460-b31b1b.svg)](https://arxiv.org/abs/2301.10460) | :heavy_minus_sign: |
| FreeCOS: Self-Supervised Learning from Fractals and Unlabeled Images for Curvilinear Object Segmentation | [![GitHub](https://img.shields.io/github/stars/TY-Shi/FreeCOS)](https://github.com/TY-Shi/FreeCOS) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07245-b31b1b.svg)](https://arxiv.org/abs/2307.07245) | :heavy_minus_sign: |
| MasQCLIP for Open-Vocabulary Universal Image Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| CTVIS: Consistent Training for Online Video Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/KainingYing/CTVIS)](https://github.com/KainingYing/CTVIS) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12616-b31b1b.svg)](https://arxiv.org/abs/2307.12616) | :heavy_minus_sign: |
| A Simple Framework for Panoptic Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Spectrum-Guided Multi-Granularity Referring Video Object Segmentation | [![GitHub](https://img.shields.io/github/stars/bo-miao/SgMg)](https://github.com/bo-miao/SgMg) | [![arXiv](https://img.shields.io/badge/arXiv-2307.13537-b31b1b.svg)](https://arxiv.org/abs/2307.13537) | :heavy_minus_sign: |
| Space Engage: Collaborative Space Supervision for Contrastive-based Semi-Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/WangChangqi98/CSS)](https://github.com/WangChangqi98/CSS) | [![arXiv](https://img.shields.io/badge/arXiv-2307.09755-b31b1b.svg)](https://arxiv.org/abs/2307.09755) | :heavy_minus_sign: |
| Adaptive Superpixel for Active Learning in Semantic Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.16817-b31b1b.svg)](https://arxiv.org/abs/2303.16817) | :heavy_minus_sign: |
| Multimodal Variational Auto-Encoder based Audio-Visual Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Isomer: Isomerous Transformer for Zero-Shot Video Object Segmentation | [![GitHub](https://img.shields.io/github/stars/DLUT-yyc/Isomer)](https://github.com/DLUT-yyc/Isomer) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06693-b31b1b.svg)](https://arxiv.org/abs/2308.06693) | :heavy_minus_sign: |
| 2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jimmy15923.github.io/mit_web/) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](http://vllab.cs.nctu.edu.tw/images/paper/iccv-yang23.pdf) | :heavy_minus_sign: |
| Foreground-Background Separation through Concept Distillation from Generative Image Foundation Models | [![GitHub](https://img.shields.io/github/stars/MischaD/fobadiffusion)](https://github.com/MischaD/fobadiffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2212.14306-b31b1b.svg)](https://arxiv.org/abs/2212.14306) | :heavy_minus_sign: |
| SegPrompt: Boosting Open-World Segmentation via Category-Level Prompt Learning | [![GitHub](https://img.shields.io/github/stars/aim-uofa/SegPrompt)](https://github.com/aim-uofa/SegPrompt) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06531-b31b1b.svg)](https://arxiv.org/abs/2308.06531) | :heavy_minus_sign: |
| Monte Carlo Linear Clustering with Single-Point Supervision is Enough for Infrared Small Target Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yeren123455.github.io/SIRST-Single-Point-Supervision/) <br /> [![GitHub](https://img.shields.io/github/stars/YeRen123455/SIRST-Single-Point-Supervision)](https://github.com/YeRen123455/SIRST-Single-Point-Supervision) | [![arXiv](https://img.shields.io/badge/arXiv-2304.04442-b31b1b.svg)](https://arxiv.org/abs/2304.04442) | :heavy_minus_sign: |
| A Simple Framework for Open-Vocabulary Segmentation and Detection | [![GitHub](https://img.shields.io/github/stars/IDEA-Research/OpenSeeD)](https://github.com/IDEA-Research/OpenSeeD) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08131-b31b1b.svg)](https://arxiv.org/abs/2303.08131) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=z4gsQw2n7iM) |
| Source-Free Depth for Object Pop-Out | [![GitHub](https://img.shields.io/github/stars/Zongwei97/PopNet)](https://github.com/Zongwei97/PopNet) | [![arXiv](https://img.shields.io/badge/arXiv-2212.05370-b31b1b.svg)](https://arxiv.org/abs/2212.05370) | :heavy_minus_sign: |
| DynaMITe: Dynamic Query Bootstrapping for Multi-Object Interactive Segmentation Transformer | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://amitrana001.github.io/DynaMITe/) <br /> [![GitHub](https://img.shields.io/github/stars/amitrana001/DynaMITe)](https://github.com/amitrana001/DynaMITe) | [![arXiv](https://img.shields.io/badge/arXiv-2304.06668-b31b1b.svg)](https://arxiv.org/abs/2304.06668) | :heavy_minus_sign: |
| Atmospheric Transmission and Thermal Inertia Induced Blind Road Segmentation with a Large-Scale Dataset TBRSD | [![GitHub](https://img.shields.io/github/stars/chenjzBUAA/TBRSD)](https://github.com/chenjzBUAA/TBRSD) | :heavy_minus_sign: | :heavy_minus_sign: |
| Informative Data Mining for One-Shot Cross-Domain Semantic Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Homography Guided Temporal Fusion for Road Line and Marking Segmentation | [![GitHub](https://img.shields.io/github/stars/ShanWang-Shan/HomoFusion)](https://github.com/ShanWang-Shan/HomoFusion) | :heavy_minus_sign: | :heavy_minus_sign: |
| Zero-Shot Semantic Segmentation with Decoupled One-Shot Network | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TCOVIS: Temporally Consistent Online Video Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/jun-long-li/TCOVIS)](https://github.com/jun-long-li/TCOVIS) | :heavy_minus_sign: | :heavy_minus_sign: |
| FPR: False Positive Rectification for Weakly Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/mt-cly/FPR)](https://github.com/mt-cly/FPR) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](http://www4.comp.polyu.edu.hk/~cslzhang/paper/ICCV23-FPR.pdf) | :heavy_minus_sign: |
| Stochastic Segmentation with Conditional Categorical Diffusion Models | [![GitHub](https://img.shields.io/github/stars/LarsDoorenbos/ccdm-stochastic-segmentation)](https://github.com/LarsDoorenbos/ccdm-stochastic-segmentation) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08888-b31b1b.svg)](https://arxiv.org/abs/2303.08888) | :heavy_minus_sign: |
| SegGPT: Segmenting Everything in Context | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/baaivision/Painter/tree/main/SegGPT) <br /> [![GitHub](https://img.shields.io/github/stars/baaivision/Painter)](https://github.com/baaivision/Painter) <br /> [![Hugging Face](https://img.shields.io/badge/🤗-SegGPT-FFD21F.svg)](https://huggingface.co/spaces/BAAI/SegGPT) | [![arXiv](https://img.shields.io/badge/arXiv-2304.03284-b31b1b.svg)](https://arxiv.org/abs/2304.03284) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zxwH0dUBKis) |
| Open-Vocabulary Panoptic Segmentation with Embedding Modulation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.11324-b31b1b.svg)](https://arxiv.org/abs/2303.11324) | :heavy_minus_sign: |
| Residual Pattern Learning for Pixel-Wise Out-of-Distribution Detection in Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/yyliu01/RPL)](https://github.com/yyliu01/RPL) | [![arXiv](https://img.shields.io/badge/arXiv-2211.14512-b31b1b.svg)](https://arxiv.org/abs/2211.14512) | :heavy_minus_sign: |
| Zero-Guidance Segmentation using Zero Segment Labels | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zero-guide-seg.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13396-b31b1b.svg)](https://arxiv.org/abs/2303.13396) | :heavy_minus_sign: |
| Model Calibration in Dense Classification with Adaptive Label Perturbation | [![GitHub](https://img.shields.io/github/stars/Carlisle-Liu/ASLP)](https://github.com/Carlisle-Liu/ASLP) | [![arXiv](https://img.shields.io/badge/arXiv-2307.13539-b31b1b.svg)](https://arxiv.org/abs/2307.13539) | :heavy_minus_sign: |
| Enhanced Soft Label for Semi-Supervised Semantic Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MixReorg: Cross-Modal Mixed Patch Reorganization is a Good Mask Learner for Open-World Semantic Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.04829-b31b1b.svg)](https://arxiv.org/abs/2308.04829) | :heavy_minus_sign: |
| DiffuMask: Synthesizing Images with Pixel-Level Annotations for Semantic Segmentation using Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://weijiawu.github.io/DiffusionMask/) <br /> [![GitHub](https://img.shields.io/github/stars/weijiawu/DiffuMask)](https://github.com/weijiawu/DiffuMask) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11681-b31b1b.svg)](https://arxiv.org/abs/2303.11681) | :heavy_minus_sign: |
| Alignment Before Aggregation: Trajectory Memory Retrieval Network for Video Object Segmentation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Semi-Supervised Semantic Segmentation under Label Noise via Diverse Learning Groups | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| SUMMIT: Source-Free Adaptation of Uni-Modal Models to Multi-Modal Targets | [![GitHub](https://img.shields.io/github/stars/csimo005/SUMMIT)](https://github.com/csimo005/SUMMIT) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11880-b31b1b.svg)](https://arxiv.org/abs/2308.11880) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LDlLq9IdoAw) |
| Class-Incremental Continual Learning for Instance Segmentation with Image-Level Weak Supervision | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Coarse-to-Fine Amodal Segmentation with Shape Prior | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jianxgao.github.io/C2F-Seg/) <br /> [![GitHub](https://img.shields.io/github/stars/JianxGao/C2F-Seg)](https://github.com/JianxGao/C2F-Seg) | [![arXiv](https://img.shields.io/badge/arXiv-2308.16825-b31b1b.svg)](https://arxiv.org/abs/2308.16825) | :heavy_minus_sign: |
| Rethinking Amodal Video Segmentation from Learning Supervised Signals with Object-Centric Representation | [![GitHub](https://img.shields.io/github/stars/kfan21/EoRaS)](https://github.com/kfan21/EoRaS) | :heavy_minus_sign: | :heavy_minus_sign: |
| DVIS: Decoupled Video Instance Segmentation Framework | [![GitHub](https://img.shields.io/github/stars/zhang-tao-whu/DVIS)](https://github.com/zhang-tao-whu/DVIS) | [![arXiv](https://img.shields.io/badge/arXiv-2306.03413-b31b1b.svg)](https://arxiv.org/abs/2306.03413) | :heavy_minus_sign: |
| 3D Segmentation of Humans in Point Clouds with Synthetic Data | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://human-3d.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2212.00786-b31b1b.svg)](https://arxiv.org/abs/2212.00786) | :heavy_minus_sign: |
| WaterMask: Instance Segmentation for Underwater Imagery | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Decoupled or End-to-End Trained Video Segmentation if Target Data is Scarce? | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Recognition: Categorization

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Cross Contrasting Feature Perturbation for Domain Generalization | [![GitHub](https://img.shields.io/github/stars/hackmebroo/CCFP)](https://github.com/hackmebroo/CCFP) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12502-b31b1b.svg)](https://arxiv.org/abs/2307.12502) | :heavy_minus_sign: |
| Flexible Visual Recognition by Evidential Modeling of Confusion and Ignorance | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.07403-b31b1b.svg)](https://arxiv.org/abs/2309.07403) | :heavy_minus_sign: |
| CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image Classification | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.16634-b31b1b.svg)](https://arxiv.org/abs/2307.16634) | :heavy_minus_sign: |
| RankMixup: Ranking-based Mixup Training for Network Calibration | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://cvlab.yonsei.ac.kr/projects/RankMixup/) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11990-b31b1b.svg)](https://arxiv.org/abs/2308.11990) | :heavy_minus_sign: |
| Label-Noise Learning with Intrinsically Long-Tailed Data | [![GitHub](https://img.shields.io/github/stars/Wakings/TABASCO)](https://github.com/Wakings/TABASCO) | [![arXiv](https://img.shields.io/badge/arXiv-2208.09833-b31b1b.svg)](https://arxiv.org/abs/2208.09833) | :heavy_minus_sign: |
| Parallel Attention Interaction Network for Few-Shot Skeleton-based Action Recognition | [![GitHub](https://img.shields.io/github/stars/starrycos/PAINet)](https://github.com/starrycos/PAINet) | :heavy_minus_sign: | :heavy_minus_sign: |
| Rethinking Mobile Block for Efficient Attention-based Models | [![GitHub](https://img.shields.io/github/stars/zhangzjn/EMO)](https://github.com/zhangzjn/EMO) | [![arXiv](https://img.shields.io/badge/arXiv-2301.01146-b31b1b.svg)](https://arxiv.org/abs/2301.01146) | :heavy_minus_sign: |
| Read-Only Prompt Optimization for Vision-Language Few-Shot Learning | [![GitHub](https://img.shields.io/github/stars/mlvlab/RPO)](https://github.com/mlvlab/RPO) | [![arXiv](https://img.shields.io/badge/arXiv-2308.14960-b31b1b.svg)](https://arxiv.org/abs/2308.14960) | :heavy_minus_sign: |
| Understanding Self-Attention Mechanism via Dynamical System Perspective | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.09939-b31b1b.svg)](https://arxiv.org/abs/2308.09939) | :heavy_minus_sign: |
| Learning in Imperfect Environment: Multi-Label Classification with Long-Tailed Distribution and Partial Labels | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.10539-b31b1b.svg)](https://arxiv.org/abs/2304.10539) | :heavy_minus_sign: |
| What do Neural Networks Learn in Image Classification? A Frequency Shortcut Perspective | [![GitHub](https://img.shields.io/github/stars/nis-research/nn-frequency-shortcuts)](https://github.com/nis-research/nn-frequency-shortcuts) | [![arXiv](https://img.shields.io/badge/arXiv-2307.09829-b31b1b.svg)](https://arxiv.org/abs/2307.09829) | :heavy_minus_sign: |
| Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing Mistake Severity | [![GitHub](https://img.shields.io/github/stars/ltong1130ztr/HAFrame)](https://github.com/ltong1130ztr/HAFrame) | [![arXiv](https://img.shields.io/badge/arXiv-2303.05689-b31b1b.svg)](https://arxiv.org/abs/2303.05689) | :heavy_minus_sign: |
| Unified Out-of-Distribution Detection: A Model-Specific Perspective | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.06813-b31b1b.svg)](https://arxiv.org/abs/2304.06813) | :heavy_minus_sign: |
| A Unified Framework for Robustness on Diverse Sampling Errors | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Scene-Aware Label Graph Learning for Multi-Label Image Classification | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Holistic Label Correction for Noisy Multi-Label Classification | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Strip-MLP: Efficient Token Interaction for Vision MLP | [![GitHub](https://img.shields.io/github/stars/Med-Process/Strip_MLP)](https://github.com/Med-Process/Strip_MLP) | [![arXiv](https://img.shields.io/badge/arXiv-2307.11458-b31b1b.svg)](https://arxiv.org/abs/2307.11458) | :heavy_minus_sign: |
| EQ-Net: Elastic Quantization Neural Networks | [![GitHub](https://img.shields.io/github/stars/xuke225/EQ-Net)](https://github.com/xuke225/EQ-Net) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07650-b31b1b.svg)](https://arxiv.org/abs/2308.07650) | :heavy_minus_sign: |
| Data-Free Knowledge Distillation for Fine-Grained Vision Categorization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Shift from Texture-Bias to Shape-Bias: edge Deformation-based Augmentation for Robust Object Recognition | [![GitHub](https://img.shields.io/github/stars/C0notSilly/-ICCV-23-Edge-Deformation-based-Online-Augmentation)](https://github.com/C0notSilly/-ICCV-23-Edge-Deformation-based-Online-Augmentation) | :heavy_minus_sign: | :heavy_minus_sign: |
| Latent-OFER: Detect, Mask, and Reconstruct with Latent Vectors for Occluded Facial Expression Recognition | [![GitHub](https://img.shields.io/github/stars/leeisack/Latent-OFER)](https://github.com/leeisack/Latent-OFER) | [![arXiv](https://img.shields.io/badge/arXiv-2307.11404-b31b1b.svg)](https://arxiv.org/abs/2307.11404) | :heavy_minus_sign: |
| DR-Tune: Improving Fine-Tuning of Pretrained Visual Models by Distribution Regularization with Semantic Calibration | [![GitHub](https://img.shields.io/github/stars/weeknan/DR-Tune)](https://github.com/weeknan/DR-Tune) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12058-b31b1b.svg)](https://arxiv.org/abs/2308.12058) | :heavy_minus_sign: |
| Understanding the Feature Norm for Out-of-Distribution Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Multi-View Active Fine-Grained Visual Recognition | [![GitHub](https://img.shields.io/github/stars/PRIS-CV/AFGR)](https://github.com/PRIS-CV/AFGR) | [![arXiv](https://img.shields.io/badge/arXiv-2206.01153-b31b1b.svg)](https://arxiv.org/abs/2206.01153) | :heavy_minus_sign: |
| DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using Pre-Trained Diffusion Models | [![GitHub](https://img.shields.io/github/stars/cure-lab/DiffGuard)](https://github.com/cure-lab/DiffGuard) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07687-b31b1b.svg)](https://arxiv.org/abs/2308.07687) | :heavy_minus_sign: |
| Task-Aware Adaptive Learning for Cross-Domain Few-Shot Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Improving Adversarial Robustness of Masked Autoencoders via Test-Time Frequency-Domain Prompting | [![GitHub](https://img.shields.io/github/stars/shikiw/RobustMAE)](https://github.com/shikiw/RobustMAE) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10315-b31b1b.svg)](https://arxiv.org/abs/2308.10315) | :heavy_minus_sign: |
| Saliency Regularization for Self-Training with Partial Annotations | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Learning Gabor Texture Features for Fine-Grained Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.05396-b31b1b.svg)](https://arxiv.org/abs/2308.05396) | :heavy_minus_sign: |
| UniFormerV2: Unlocking the Potential of Image ViTs for Video Understanding | [![GitHub](https://img.shields.io/github/stars/OpenGVLab/UniFormerV2)](https://github.com/OpenGVLab/UniFormerV2) | [![arXiv](https://img.shields.io/badge/arXiv-2211.09552-b31b1b.svg)](https://arxiv.org/abs/2211.09552) | :heavy_minus_sign: |
| RankMatch: Fostering Confidence and Consistency in Learning with Noisy Labels | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MetaGCD: Learning to Continually Learn in Generalized Category Discovery | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.11063-b31b1b.svg)](https://arxiv.org/abs/2308.11063) | :heavy_minus_sign: |
| FerKD: Surgical Label Adaptation for Efficient Distillation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Point-Query Quadtree for Crowd Counting, Localization, and more | [![GitHub](https://img.shields.io/github/stars/cxliu0/PET)](https://github.com/cxliu0/PET) | [![arXiv](https://img.shields.io/badge/arXiv-2308.13814-b31b1b.svg)](https://arxiv.org/abs/2308.13814) | :heavy_minus_sign: |
| Nearest Neighbor Guidance for Out-of-Distribution Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Bayesian Optimization Meets Self-Distillation | [![GitHub](https://img.shields.io/github/stars/sooperset/boss)](https://github.com/sooperset/boss) | [![arXiv](https://img.shields.io/badge/arXiv-2304.12666-b31b1b.svg)](https://arxiv.org/abs/2304.12666) | :heavy_minus_sign: |
| When Prompt-based Incremental Learning does not Meet Strong Pretraining | [![GitHub](https://img.shields.io/github/stars/TOM-tym/APG)](https://github.com/TOM-tym/APG) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10445-b31b1b.svg)](https://arxiv.org/abs/2308.10445) | :heavy_minus_sign: |
| When to Learn what: Model-Adaptive Data Augmentation Curriculum | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Parametric Information Maximization for Generalized Category Discovery | [![GitHub](https://img.shields.io/github/stars/ThalesGroup/pim-generalized-category-discovery)](https://github.com/ThalesGroup/pim-generalized-category-discovery) | [![arXiv](https://img.shields.io/badge/arXiv-2212.00334-b31b1b.svg)](https://arxiv.org/abs/2212.00334) | :heavy_minus_sign: |
| Boosting Few-Shot Action Recognition with Graph-Guided Hybrid Matching | [![GitHub](https://img.shields.io/github/stars/jiazheng-xing/GgHM)](https://github.com/jiazheng-xing/GgHM) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09346-b31b1b.svg)](https://arxiv.org/abs/2308.09346) | :heavy_minus_sign: |
| Domain Generalization via Rationale Invariance | [![GitHub](https://img.shields.io/github/stars/liangchen527/RIDG)](https://github.com/liangchen527/RIDG) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11158-b31b1b.svg)](https://arxiv.org/abs/2308.11158) | :heavy_minus_sign: |
| Masked Spiking Transformer | [![GitHub](https://img.shields.io/github/stars/bic-L/Masked-Spiking-Transformer)](https://github.com/bic-L/Masked-Spiking-Transformer) | [![arXiv](https://img.shields.io/badge/arXiv-2210.01208-b31b1b.svg)](https://arxiv.org/abs/2210.01208) | :heavy_minus_sign: |
| Prototype Reminiscence and Augmented Asymmetric Knowledge Aggregation for Non-Exemplar Class-Incremental Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Distilled Reverse Attention Network for Open-World Compositional Zero-Shot Learning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.00404-b31b1b.svg)](https://arxiv.org/abs/2303.00404) | :heavy_minus_sign: |
| Candidate-Aware Selective Disambiguation based on Normalized Entropy for Instance-Dependent Partial-Label Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| CLIPN for Zero-Shot OOD Detection: Teaching CLIP to Say No | [![GitHub](https://img.shields.io/github/stars/xmed-lab/CLIPN)](https://github.com/xmed-lab/CLIPN) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12213-b31b1b.svg)](https://arxiv.org/abs/2308.12213) | :heavy_minus_sign: |
| Self-Similarity Driven Scale-Invariant Learning for Weakly Supervised Person Search | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2302.12986-b31b1b.svg)](https://arxiv.org/abs/2302.12986) | :heavy_minus_sign: |
| Sample-Wise Label Confidence Incorporation for Learning with Noisy Labels | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Combating Noisy Labels with Sample Selection by Mining High-Discrepancy Examples | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Spatial-Aware Token for Weakly Supervised Object Localization | [![GitHub](https://img.shields.io/github/stars/wpy1999/SAT)](https://github.com/wpy1999/SAT) | [![arXiv](https://img.shields.io/badge/arXiv-2303.10438-b31b1b.svg)](https://arxiv.org/abs/2303.10438) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Explainable AI for CV

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Towards Improved Input Masking for Convolutional Neural Networks | [![GitHub](https://img.shields.io/github/stars/SriramB-98/layer_masking)](https://github.com/SriramB-98/layer_masking) | [![arXiv](https://img.shields.io/badge/arXiv-2211.14646-b31b1b.svg)](https://arxiv.org/abs/2211.14646) | :heavy_minus_sign: |
| PDiscoNet: Semantically Consistent Part Discovery for Fine-Grained Recognition | [![GitHub](https://img.shields.io/github/stars/robertdvdk/part_detection)](https://github.com/robertdvdk/part_detection) | [![HAL Science](https://img.shields.io/badge/hal-science-040060.svg)](https://hal.inrae.fr/hal-04183747) | :heavy_minus_sign: |
| Corrupting Neuron Explanations of Deep Visual Features | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| ICICLE: Interpretable Class Incremental Continual Learning | [![GitHub](https://img.shields.io/github/stars/gmum/ICICLE)](https://github.com/gmum/ICICLE) | [![arXiv](https://img.shields.io/badge/arXiv-2303.07811-b31b1b.svg)](https://arxiv.org/abs/2303.07811) | :heavy_minus_sign: |
| ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.eml-unitue.de/publication/ProbVLM) <br /> [![GitHub](https://img.shields.io/github/stars/ExplainableML/ProbVLM)](https://github.com/ExplainableML/ProbVLM) | [![arXiv](https://img.shields.io/badge/arXiv-2307.00398-b31b1b.svg)](https://arxiv.org/abs/2307.00398) | :heavy_minus_sign: |
| Out-of-Distribution Detection for Monocular Depth Estimation | [![GitHub](https://img.shields.io/github/stars/jhornauer/mde_ood)](https://github.com/jhornauer/mde_ood) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06072-b31b1b.svg)](https://arxiv.org/abs/2308.06072) | :heavy_minus_sign: |
| Using Explanations to Guide Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.11932-b31b1b.svg)](https://arxiv.org/abs/2303.11932) | :heavy_minus_sign: |
| Rosetta Neurons: Mining the Common Units in a Model Zoo | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yossigandelsman.github.io/rosetta_neurons/) <br /> [![GitHub](https://img.shields.io/github/stars/yossigandelsman/rosetta_neurons)](https://github.com/yossigandelsman/rosetta_neurons) | [![arXiv](https://img.shields.io/badge/arXiv-2306.09346-b31b1b.svg)](https://arxiv.org/abs/2306.09346) | :heavy_minus_sign: |
| Prototype-based Dataset Comparison | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nanne.github.io/ProtoSim/) <br /> [![GitHub](https://img.shields.io/github/stars/Nanne/ProtoSim)](https://github.com/Nanne/ProtoSim) | [![arXiv](https://img.shields.io/badge/arXiv-2309.02401-b31b1b.svg)](https://arxiv.org/abs/2309.02401) | :heavy_minus_sign: |
| Learning to Identify Critical States for Reinforcement Learning from Videos | [![GitHub](https://img.shields.io/github/stars/AI-Initiative-KAUST/VideoRLCS)](https://github.com/AI-Initiative-KAUST/VideoRLCS) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07795-b31b1b.svg)](https://arxiv.org/abs/2308.07795) | :heavy_minus_sign: |
| Leaping Into Memories: Space-Time Deep Feature Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://alexandrosstergiou.github.io/project_pages/LEAPS/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/alexandrosstergiou/Leaping-Into-Memories)](https://github.com/alexandrosstergiou/Leaping-Into-Memories) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09941-b31b1b.svg)](https://arxiv.org/abs/2303.09941) | :heavy_minus_sign: |
| MAGI: Multi-Annotated Explanation-Guided Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability | [![GitHub](https://img.shields.io/github/stars/havelhuang/Eval_XAI_Robustness)](https://github.com/havelhuang/Eval_XAI_Robustness) | [![arXiv](https://img.shields.io/badge/arXiv-2208.09418-b31b1b.svg)](https://arxiv.org/abs/2208.09418) | :heavy_minus_sign: |
| Do BLIP and Stable Diffusion Understand Each Other? | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dalleflamingo.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2212.12249-b31b1b.svg)](https://arxiv.org/abs/2212.12249) | :heavy_minus_sign: |
| Evaluation and Improvement of Interpretability for Self-Explainable Part-Prototype Networks | [![GitHub](https://img.shields.io/github/stars/hqhQAQ/EvalProtoPNet)](https://github.com/hqhQAQ/EvalProtoPNet) | [![arXiv](https://img.shields.io/badge/arXiv-2212.05946-b31b1b.svg)](https://arxiv.org/abs/2212.05946) | :heavy_minus_sign: |
| MoreauGrad: Sparse and Robust Interpretation of Neural Networks via Moreau Envelope | [![GitHub](https://img.shields.io/github/stars/buyeah1109/MoreauGrad)](https://github.com/buyeah1109/MoreauGrad) | [![arXiv](https://img.shields.io/badge/arXiv-2302.05294-b31b1b.svg)](https://arxiv.org/abs/2302.05294) | :heavy_minus_sign: |
| Towards Understanding the Generalization of Deepfake Detectors from a Game-Theoretical View | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Counterfactual-based Saliency Map: Towards Visual Contrastive Explanations for Neural Networks | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Beyond Single Path Integrated Gradients for Reliable Input Attribution via Randomized Path Sampling | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Learning Support and Trivial Prototypes for Interpretable Image Classification | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2301.04011-b31b1b.svg)](https://arxiv.org/abs/2301.04011) | :heavy_minus_sign: |
| Visual Explanations via Iterated Integrated Gradients | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Neural Generative Models

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Unsupervised Compositional Concepts Discovery with Text-to-Image Generative Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://energy-based-model.github.io/unsupervised-concept-discovery/) <br /> [![GitHub](https://img.shields.io/github/stars/nanlliu/Unsupervised-Compositional-Concepts-Discovery)](https://github.com/nanlliu/Unsupervised-Compositional-Concepts-Discovery) | [![arXiv](https://img.shields.io/badge/arXiv-2306.05357-b31b1b.svg)](https://arxiv.org/abs/2306.05357) | :heavy_minus_sign: |
| Better Aligning Text-to-Image Models with Human Preference | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tgxs002.github.io/align_sd_web/) <br /> [![GitHub](https://img.shields.io/github/stars/tgxs002/align_sd)](https://github.com/tgxs002/align_sd) | [![arXiv](https://img.shields.io/badge/arXiv-2303.14420-b31b1b.svg)](https://arxiv.org/abs/2303.14420) | :heavy_minus_sign: |
| DLT: Conditioned Layout Generation with Joint Discrete-Continuous Diffusion Layout Transformer | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wix-incubator.github.io/DLT/) <br /> [![GitHub](https://img.shields.io/github/stars/wix-incubator/DLT)](https://github.com/wix-incubator/DLT) | [![arXiv](https://img.shields.io/badge/arXiv-2303.03755-b31b1b.svg)](https://arxiv.org/abs/2303.03755) | :heavy_minus_sign: |
| Anti-DreamBooth: Protecting users from Personalized Text-to-Image Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://anti-dreambooth.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/VinAIResearch/Anti-DreamBooth)](https://github.com/VinAIResearch/Anti-DreamBooth) | [![arXiv](https://img.shields.io/badge/arXiv-2303.15433-b31b1b.svg)](https://arxiv.org/abs/2303.15433) | :heavy_minus_sign: |
| GECCO: Geometrically-Conditioned Point Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jatentaki.github.io/publication/10-03-2023) | [![arXiv](https://img.shields.io/badge/arXiv-2303.05916-b31b1b.svg)](https://arxiv.org/abs/2303.05916) | :heavy_minus_sign: |
| DiffDreamer: Towards Consistent Unsupervised Single-View Scene Extrapolation with Conditional Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://primecai.github.io/diffdreamer) <br /> [![GitHub](https://img.shields.io/github/stars/primecai/DiffDreamer)](https://github.com/primecai/DiffDreamer) | [![arXiv](https://img.shields.io/badge/arXiv-2211.12131-b31b1b.svg)](https://arxiv.org/abs/2211.12131) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UukyiAqlwcw) |
| Controllable Human Motion Synthesis via Guided Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://korrawe.github.io/gmd-project/) <br /> [![GitHub](https://img.shields.io/github/stars/korrawe/guided-motion-diffusion)](https://github.com/korrawe/guided-motion-diffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2305.12577-b31b1b.svg)](https://arxiv.org/abs/2305.12577) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=giw0pLIKdsA) |
| COOP: Decoupling and Coupling of Whole-Body Grasping Pose Generation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Zero-Shot Spatial Layout Conditioning for Text-to-Image Diffusion Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.13754-b31b1b.svg)](https://arxiv.org/abs/2306.13754) | :heavy_minus_sign: |
| StyleDomain: Efficient and Lightweight Parameterizations of StyleGAN for One-Shot and Few-Shot Domain Adaptation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2212.10229-b31b1b.svg)](https://arxiv.org/abs/2212.10229) | :heavy_minus_sign: |
| GRAM-HD: 3D-Consistent Image Generation at High Resolution with Generative Radiance Manifolds | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jeffreyxiang.github.io/GRAM-HD/) | [![arXiv](https://img.shields.io/badge/arXiv-2206.07255-b31b1b.svg)](https://arxiv.org/abs/2206.07255) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Uqzs4uN6v8M) |
| Your Diffusion Model is Secretly a Zero-Shot Classifier | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://diffusion-classifier.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/diffusion-classifier/diffusion-classifier)](https://github.com/diffusion-classifier/diffusion-classifier) | [![arXiv](https://img.shields.io/badge/arXiv-2303.16203-b31b1b.svg)](https://arxiv.org/abs/2303.16203) | :heavy_minus_sign: |
| Learning Hierarchical Features with Joint Latent Space Energy-based Prior | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| ActFormer: A GAN-based Transformer towards General Action-Conditioned 3D Human Motion Generation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2203.07706-b31b1b.svg)](https://arxiv.org/abs/2203.07706) | :heavy_minus_sign: |
| Landscape Learning for Neural Network Inversion | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2206.09027-b31b1b.svg)](https://arxiv.org/abs/2206.09027) | :heavy_minus_sign: |
| Diffusion in Style | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Diffusion-SDF: Conditional Generative Modeling of Signed Distance Functions | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://light.princeton.edu/publication/diffusion-sdf/) <br /> [![GitHub](https://img.shields.io/github/stars/princeton-computational-imaging/Diffusion-SDF)](https://github.com/princeton-computational-imaging/Diffusion-SDF) | [![arXiv](https://img.shields.io/badge/arXiv-2211.13757-b31b1b.svg)](https://arxiv.org/abs/2211.13757) | :heavy_minus_sign: |
| GETAvatar: Generative Textured Meshes for Animatable Human Avatars | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| A-STAR: Test-Time <i>A</i>ttention <i>S</i>egrega<i>t</i>ion and <i>R</i>etention for Text-to-Image Synthesis | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.14544-b31b1b.svg)](https://arxiv.org/abs/2306.14544) | :heavy_minus_sign: |
| TF-ICON: Diffusion-based Training-Free Cross-Domain Image Composition | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://shilin-lu.github.io/tf-icon.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/Shilin-LU/TF-ICON)](https://github.com/Shilin-LU/TF-ICON) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12493-b31b1b.svg)](https://arxiv.org/abs/2307.12493) | :heavy_minus_sign: |
| Breaking The Limits of Text-Conditioned 3D Motion Synthesis with Elaborative Descriptions | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| BeLFusion: Latent Diffusion for Behavior-Driven Human Motion Prediction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://barquerogerman.github.io/BeLFusion/) <br /> [![GitHub](https://img.shields.io/github/stars/BarqueroGerman/BeLFusion)](https://github.com/BarqueroGerman/BeLFusion) | [![arXiv](https://img.shields.io/badge/arXiv-2211.14304-b31b1b.svg)](https://arxiv.org/abs/2211.14304) | :heavy_minus_sign: |
| Delta Denoising Score | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://delta-denoising-score.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2304.07090-b31b1b.svg)](https://arxiv.org/abs/2304.07090) | :heavy_minus_sign: |
| Mimic3D: Thriving 3D-Aware GANs via 3D-to-2D Imitation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://seanchenxy.github.io/Mimic3DWeb/) <br /> [![GitHub](https://img.shields.io/github/stars/SeanChenxy/Mimic3D)](https://github.com/SeanChenxy/Mimic3D) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09036-b31b1b.svg)](https://arxiv.org/abs/2303.09036) | :heavy_minus_sign: |
| DreamBooth3D: Subject-Driven Text-to-3D Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dreambooth3d.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13508-b31b1b.svg)](https://arxiv.org/abs/2303.13508) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kKVDrbfvOoA) |
| Feature Proliferation the Cancer in StyleGAN and its Treatments | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Unsupervised Facial Performance Editing via Vector-Quantized StyleGAN Representations | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| 3D-Aware Image Generation using 2D Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jeffreyxiang.github.io/ivid/) <br /> [![GitHub](https://img.shields.io/github/stars/JeffreyXiang/ivid)](https://github.com/JeffreyXiang/ivid) | [![arXiv](https://img.shields.io/badge/arXiv-2303.17905-b31b1b.svg)](https://arxiv.org/abs/2303.17905) | :heavy_minus_sign: |
| Neural Collage Transfer: Artistic Reconstruction via Material Manipulation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption | [![GitHub](https://img.shields.io/github/stars/sjtuplayer/few-shot-diffusion)](https://github.com/sjtuplayer/few-shot-diffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2309.03729-b31b1b.svg)](https://arxiv.org/abs/2309.03729) | :heavy_minus_sign: |
| Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lakonik.github.io/ssdnerf/) <br /> [![GitHub](https://img.shields.io/github/stars/Lakonik/SSDNeRF)](https://github.com/Lakonik/SSDNeRF) | [![arXiv](https://img.shields.io/badge/arXiv-2304.06714-b31b1b.svg)](https://arxiv.org/abs/2304.06714) | :heavy_minus_sign: |
| Erasing Concepts from Diffusion Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://erasing.baulab.info/) <br /> [![GitHub](https://img.shields.io/github/stars/rohitgandikota/erasing)](https://github.com/rohitgandikota/erasing) | [![arXiv](https://img.shields.io/badge/arXiv-2303.07345-b31b1b.svg)](https://arxiv.org/abs/2303.07345) | :heavy_minus_sign: |
| Make Encoder Great Again in 3D GAN Inversion through Geometry and Occlusion-Aware Encoding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://eg3d-goae.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/jiangyzy/GOAE)](https://github.com/jiangyzy/GOAE) | [![arXiv](https://img.shields.io/badge/arXiv-2303.12326-b31b1b.svg)](https://arxiv.org/abs/2303.12326) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CptQDMqM9Pc) |
| HairNeRF: Geometry-Aware Hair Swapped Image Synthesis | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision and Language

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| SMAUG: Sparse Masked Autoencoder for Efficient Video-Language Pre-Training | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2211.11446-b31b1b.svg)](https://arxiv.org/abs/2211.11446) | :heavy_minus_sign: |
| DiffusionRet: Generative Text-Video Retrieval with Diffusion Model | [![GitHub](https://img.shields.io/github/stars/jpthu17/DiffusionRet)](https://github.com/jpthu17/DiffusionRet) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09867-b31b1b.svg)](https://arxiv.org/abs/2303.09867) | :heavy_minus_sign: |
| Explore and Tell: Embodied Visual Captioning in 3D Environments | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://aim3-ruc.github.io/ExploreAndTell/) <br /> [![GitHub](https://img.shields.io/github/stars/HAWLYQ/ET-Cap)](https://github.com/HAWLYQ/ET-Cap) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10447-b31b1b.svg)](https://arxiv.org/abs/2308.10447) | :heavy_minus_sign: |
| Distilling Large Vision-Language Model with Out-of-Distribution Generalizability | [![GitHub](https://img.shields.io/github/stars/xuanlinli17/large_vlm_distillation_ood)](https://github.com/xuanlinli17/large_vlm_distillation_ood) | [![arXiv](https://img.shields.io/badge/arXiv-2307.03135-b31b1b.svg)](https://arxiv.org/abs/2307.03135) | :heavy_minus_sign: |
| Learning Trajectory-Word Alignments for Video-Language Tasks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2301.01953-b31b1b.svg)](https://arxiv.org/abs/2301.01953) | :heavy_minus_sign: |
| Variational Causal Inference Network for Explanatory Visual Question Answering | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TextManiA: Enriching Visual Feature by Text-Driven Manifold Augmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://textmania.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/postech-ami/TextManiA)](https://github.com/postech-ami/TextManiA) | [![arXiv](https://img.shields.io/badge/arXiv-2307.14611-b31b1b.svg)](https://arxiv.org/abs/2307.14611) | :heavy_minus_sign: |
| UniRef: A Unified Model for Reference-based Object Segmentation Tasks | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.06571-b31b1b.svg)](https://arxiv.org/abs/2303.06571) | :heavy_minus_sign: |
| Misalign, Contrast then Distill: Rethinking Misalignments in Language-Image Pre-Training | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Toward Multi-Granularity Decision-Making: Explicit Visual Reasoning with Hierarchical Knowledge | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| VL-Match: Enhancing Vision-Language Pretraining with Token-Level and Instance-Level Matching | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Moment Detection in Long Tutorial Videos | [![GitHub](https://img.shields.io/github/stars/ioanacroi/longmoment-detr)](https://github.com/ioanacroi/longmoment-detr) | :heavy_minus_sign: | :heavy_minus_sign: |
| Not All Features Matter: Enhancing Few-Shot CLIP with Adaptive Prior Refinement | [![GitHub](https://img.shields.io/github/stars/yangyangyang127/APE)](https://github.com/yangyangyang127/APE) | [![arXiv](https://img.shields.io/badge/arXiv-2304.01195-b31b1b.svg)](https://arxiv.org/abs/2304.01195) | :heavy_minus_sign: |
| Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://whoops-benchmark.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2303.07274-b31b1b.svg)](https://arxiv.org/abs/2303.07274) | :heavy_minus_sign: |
| Advancing Referring Expression Segmentation Beyond Single Image | [![GitHub](https://img.shields.io/github/stars/yixuan730/group-res)](https://github.com/yixuan730/group-res) | [![arXiv](https://img.shields.io/badge/arXiv-2305.12452-b31b1b.svg)](https://arxiv.org/abs/2305.12452) | :heavy_minus_sign: |
| CLIPoint: Adapting CLIP for Powerful 3D Open-World Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Unsupervised Prompt Tuning for Text-Driven Object Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Distilling Coarse-to-Fine Semantic Matching Knowledge for Weakly Supervised 3D Visual Grounding | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.09267-b31b1b.svg)](https://arxiv.org/abs/2307.09267) | :heavy_minus_sign: |
| I can't Believe there's no Images! Learning Visual Tasks using Only Language Data | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://prior.allenai.org/projects/close) <br /> [![GitHub](https://img.shields.io/github/stars/allenai/close)](https://github.com/allenai/close) | [![arXiv](https://img.shields.io/badge/arXiv-2211.09778-b31b1b.svg)](https://arxiv.org/abs/2211.09778) | :heavy_minus_sign: |
| Learning Cross-Modal Affinity for Referring Video Object Segmentation Targeting Limited Samples | [![GitHub](https://img.shields.io/github/stars/hengliusky/Few_shot_RVOS)](https://github.com/hengliusky/Few_shot_RVOS) | [![arXiv](https://img.shields.io/badge/arXiv-2309.02041-b31b1b.svg)](https://arxiv.org/abs/2309.02041) | :heavy_minus_sign: |
| MeViS: A Large-Scale Benchmark for Video Segmentation with Motion Expressions | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://henghuiding.github.io/MeViS/) <br /> [![GitHub](https://img.shields.io/github/stars/henghuiding/MeViS)](https://github.com/henghuiding/MeViS) | [![arXiv](https://img.shields.io/badge/arXiv-2308.08544-b31b1b.svg)](https://arxiv.org/abs/2308.08544) | :heavy_minus_sign: |
| Diverse Data Augmentation with Diffusions for Effective Test-Time Prompt Tuning | [![GitHub](https://img.shields.io/github/stars/chunmeifeng/DiffTPT)](https://github.com/chunmeifeng/DiffTPT) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06038-b31b1b.svg)](https://arxiv.org/abs/2308.06038) | :heavy_minus_sign: |
| ShapeScaffolder: Structure-Aware 3D Shape Generation from Text | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://www.yongliangyang.net/docs/shapescaffolder_iccv23.pdf) | :heavy_minus_sign: |
| SuS-X: Training-Free Name-Only Transfer of Vision-Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vishaal27.github.io/SuS-X-webpage/) <br /> [![GitHub](https://img.shields.io/github/stars/vishaal27/SuS-X)](https://github.com/vishaal27/SuS-X) | [![arXiv](https://img.shields.io/badge/arXiv-2211.16198-b31b1b.svg)](https://arxiv.org/abs/2211.16198) | :heavy_minus_sign: |
| BEVBert: Multimodal Map Pre-Training for Language-Guided Navigation | [![GitHub](https://img.shields.io/github/stars/MarSaKi/VLN-BEVBert)](https://github.com/MarSaKi/VLN-BEVBert) | [![arXiv](https://img.shields.io/badge/arXiv-2212.04385-b31b1b.svg)](https://arxiv.org/abs/2212.04385) | :heavy_minus_sign: |
| X-Mesh: Towards Fast and Accurate Text-Driven 3D Stylization via Dynamic Textual Guidance | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xmu-xiaoma666.github.io/Projects/X-Mesh/) <br /> [![GitHub](https://img.shields.io/github/stars/xmu-xiaoma666/X-Mesh)](https://github.com/xmu-xiaoma666/X-Mesh) | [![arXiv](https://img.shields.io/badge/arXiv-2303.15764-b31b1b.svg)](https://arxiv.org/abs/2303.15764) | :heavy_minus_sign: |
| OnlineRefer: A Simple Online Baseline for Referring Video Object Segmentation | [![GitHub](https://img.shields.io/github/stars/wudongming97/OnlineRefer)](https://github.com/wudongming97/OnlineRefer) | [![arXiv](https://img.shields.io/badge/arXiv-2307.09356-b31b1b.svg)](https://arxiv.org/abs/2307.09356) | :heavy_minus_sign: |
| Attentive Mask CLIP | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2212.08653-b31b1b.svg)](https://arxiv.org/abs/2212.08653) | :heavy_minus_sign: |
| Knowledge Proxy Intervention for Deconfounded Video Question Answering | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| UniVTG: Towards Unified Video-Language Temporal Grounding | [![GitHub](https://img.shields.io/github/stars/showlab/UniVTG)](https://github.com/showlab/UniVTG) | [![arXiv](https://img.shields.io/badge/arXiv-2307.16715-b31b1b.svg)](https://arxiv.org/abs/2307.16715) | :heavy_minus_sign: |
| Self-Supervised Cross-View Representation Reconstruction for Change Captioning | [![GitHub](https://img.shields.io/github/stars/tuyunbin/SCORER)](https://github.com/tuyunbin/SCORER) | :heavy_minus_sign: | :heavy_minus_sign: |
| Unified Coarse-to-Fine Alignment for Video-Text Retrieval | [![GitHub](https://img.shields.io/github/stars/Ziyang412/UCoFiA)](https://github.com/Ziyang412/UCoFiA) | :heavy_minus_sign: | :heavy_minus_sign: |
| Confidence-Aware Pseudo-Label Learning for Weakly Supervised Visual Grounding | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TextPSG: Panoptic Scene Graph Generation from Textual Descriptions | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MAtch, eXpand and Improve: Unsupervised Finetuning for Zero-Shot Action Recognition with Language Knowledge | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wlin-at.github.io/maxi) <br /> [![GitHub](https://img.shields.io/github/stars/wlin-at/MAXI)](https://github.com/wlin-at/MAXI) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08914-b31b1b.svg)](https://arxiv.org/abs/2303.08914) | :heavy_minus_sign: |
| Unify, Align and Refine: Multi-Level Semantic Alignment for Radiology Report Generation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.15932-b31b1b.svg)](https://arxiv.org/abs/2303.15932) | :heavy_minus_sign: |
| Transferring Visual Knowledge with Pre-Trained Models for Multimodal Machine Translation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://devaansh100.github.io/projects/cliptrans/) <br /> [![GitHub](https://img.shields.io/github/stars/devaansh100/CLIPTrans)](https://github.com/devaansh100/CLIPTrans) | [![arXiv](https://img.shields.io/badge/arXiv-2308.15226-b31b1b.svg)](https://arxiv.org/abs/2308.15226) | :heavy_minus_sign: |
| Learning Human-Human Interactions in Images from Weak Textual Supervision | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tau-vailab.github.io/learning-interactions/) <br /> [![GitHub](https://img.shields.io/github/stars/TAU-VAILab/learning-interactions)](https://github.com/TAU-VAILab/learning-interactions) | [![arXiv](https://img.shields.io/badge/arXiv-2304.14104-b31b1b.svg)](https://arxiv.org/abs/2304.14104) | :heavy_minus_sign: |
| BUS: Efficient and Effective Vision-Language Pretraining with Bottom-Up Patch Summarization | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.08504-b31b1b.svg)](https://arxiv.org/abs/2307.08504) | :heavy_minus_sign: |
| 3D-VisTA: Pre-Trained Transformer for 3D Vision and Text Alignment | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://3d-vista.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/3d-vista/3D-VisTA)](https://github.com/3d-vista/3D-VisTA) | [![arXiv](https://img.shields.io/badge/arXiv-2308.04352-b31b1b.svg)](https://arxiv.org/abs/2308.04352) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=uUtMaoif8DQ&t=1s) |
| ALIP: Adaptive Language-Image Pre-Training with Synthetic Caption | [![GitHub](https://img.shields.io/github/stars/deepglint/ALIP)](https://github.com/deepglint/ALIP) | [![arXiv](https://img.shields.io/badge/arXiv-2308.08428-b31b1b.svg)](https://arxiv.org/abs/2308.08428) | :heavy_minus_sign: |
| LoGoPrompt: Synthetic Text Images can be Good Visual Prompts for Vision-Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chengshiest.github.io/logo/) | [![arXiv](https://img.shields.io/badge/arXiv-2309.01155-b31b1b.svg)](https://arxiv.org/abs/2309.01155) | :heavy_minus_sign: |
| Noise-Aware Learning from Web-Crawled Image-Text Data for Image Captioning | [![GitHub](https://img.shields.io/github/stars/kakaobrain/noc)](https://github.com/kakaobrain/noc) | [![arXiv](https://img.shields.io/badge/arXiv-2212.13563-b31b1b.svg)](https://arxiv.org/abs/2212.13563) | :heavy_minus_sign: |
| Decouple Before Interact: Multi-Modal Prompt Learning for Continual Visual Question Answering | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Prompt-Guided Image Captioning for VQA with GPT-3 | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yushi-hu.github.io/promptcap_demo/) <br /> [![GitHub](https://img.shields.io/github/stars/Yushi-Hu/PromptCap)](https://github.com/Yushi-Hu/PromptCap) | [![arXiv](https://img.shields.io/badge/arXiv-2211.09699-b31b1b.svg)](https://arxiv.org/abs/2211.09699) | :heavy_minus_sign: |
| Grounded Image Text Matching with Mismatched Relation Reasoning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.01236-b31b1b.svg)](https://arxiv.org/abs/2308.01236) | :heavy_minus_sign: |
| GePSAn: Generative Procedure Step Anticipation in Cooking Videos | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dki-lab.github.io/LLM-Planner/) <br /> [![GitHub](https://img.shields.io/github/stars/OSU-NLP-Group/LLM-Planner)](https://github.com/OSU-NLP-Group/LLM-Planner) | [![arXiv](https://img.shields.io/badge/arXiv-2212.04088-b31b1b.svg)](https://arxiv.org/abs/2212.04088) | :heavy_minus_sign: |
| VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity Control | [![GitHub](https://img.shields.io/github/stars/HenryHZY/VL-PET)](https://github.com/HenryHZY/VL-PET) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09804-b31b1b.svg)](https://arxiv.org/abs/2308.09804) | :heavy_minus_sign: |
| With a Little Help from Your own Past: Prototypical Memory Networks for Image Captioning | [![GitHub](https://img.shields.io/github/stars/aimagelab/PMA-Net)](https://github.com/aimagelab/PMA-Net) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12383-b31b1b.svg)](https://arxiv.org/abs/2308.12383) | :heavy_minus_sign: |
| Improving Zero-Shot Generalization for CLIP with Synthesized Prompts | [![GitHub](https://img.shields.io/github/stars/mrflogs/SHIP)](https://github.com/mrflogs/SHIP) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07397-b31b1b.svg)](https://arxiv.org/abs/2307.07397) | :heavy_minus_sign: |
| DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generation Models | [![GitHub](https://img.shields.io/github/stars/j-min/DallEval)](https://github.com/j-min/DallEval) | [![arXiv](https://img.shields.io/badge/arXiv-2202.04053-b31b1b.svg)](https://arxiv.org/abs/2202.04053) | :heavy_minus_sign: |
| Learning Navigational Visual Representations with Semantic Map Supervision | [![GitHub](https://img.shields.io/github/stars/YicongHong/Ego2Map-NaViT)](https://github.com/YicongHong/Ego2Map-NaViT) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12335-b31b1b.svg)](https://arxiv.org/abs/2307.12335) | :heavy_minus_sign: |
| CoTDet: Affordance Knowledge Prompting for Task Driven Object Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://toneyaya.github.io/cotdet/) | [![arXiv](https://img.shields.io/badge/arXiv-2309.01093-b31b1b.svg)](https://arxiv.org/abs/2309.01093) | :heavy_minus_sign: |
| Open Set Video HOI detection from Action-Centric Chain-of-Look Prompting | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Learning Concise and Descriptive Attributes for Visual Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.03685-b31b1b.svg)](https://arxiv.org/abs/2308.03685) | :heavy_minus_sign: |
| Open-Vocabulary Video Question Answering: A New Benchmark for Evaluating the Generalizability of Video Question Answering Models | [![GitHub](https://img.shields.io/github/stars/mlvlab/OVQA)](https://github.com/mlvlab/OVQA) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09363-b31b1b.svg)](https://arxiv.org/abs/2308.09363) | :heavy_minus_sign: |
| Encyclopedic VQA: Visual Questions About Detailed Properties of Fine-Grained Categories | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/google-research/google-research/tree/master/encyclopedic_vqa) | [![arXiv](https://img.shields.io/badge/arXiv-2306.09224-b31b1b.svg)](https://arxiv.org/abs/2306.09224) | :heavy_minus_sign: |
| Story Visualization by Online Text Augmentation with Context Memory | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dcahn12.github.io/projects/CMOTA/) <br /> [![GitHub](https://img.shields.io/github/stars/yonseivnl/cmota)](https://github.com/yonseivnl/cmota) | [![arXiv](https://img.shields.io/badge/arXiv-2308.07575-b31b1b.svg)](https://arxiv.org/abs/2308.07575) | :heavy_minus_sign: |
| Transferable Decoding with Visual Entities for Zero-Shot Image Captioning | [![GitHub](https://img.shields.io/github/stars/FeiElysia/ViECap)](https://github.com/FeiElysia/ViECap) | [![arXiv](https://img.shields.io/badge/arXiv-2307.16525-b31b1b.svg)](https://arxiv.org/abs/2307.16525) | :heavy_minus_sign: |
| Too Large; Data Reduction for Vision-Language Pre-Training | [![GitHub](https://img.shields.io/github/stars/showlab/datacentric.vlp)](https://github.com/showlab/datacentric.vlp) | [![arXiv](https://img.shields.io/badge/arXiv-2305.20087-b31b1b.svg)](https://arxiv.org/abs/2305.20087) | :heavy_minus_sign: |
| ViLTA: Enhancing Vision-Language Pre-Training through Textual Augmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.16689-b31b1b.svg)](https://arxiv.org/abs/2308.16689) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision, Graphics, and Robotics

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Learning Conditional Control for Pretrained Text-to-Image Diffusion Models | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Factorized Inverse Path Tracing for Efficient and Accurate Material-Lighting Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jerrypiglet.github.io/fipt-ucsd/) <br /> [![GitHub](https://img.shields.io/github/stars/lwwu2/fipt)](https://github.com/lwwu2/fipt) | [![arXiv](https://img.shields.io/badge/arXiv-2304.05669-b31b1b.svg)](https://arxiv.org/abs/2304.05669) |  |
| Manipulate by Seeing: Creating Manipulation Controllers from Pre-Trained Representations | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://agi-labs.github.io/manipulate-by-seeing/) <br /> [![GitHub](https://img.shields.io/github/stars/AGI-Labs/manipulate-by-seeing)](https://github.com/AGI-Labs/manipulate-by-seeing) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08135-b31b1b.svg)](https://arxiv.org/abs/2303.08135) | :heavy_minus_sign: |
| 3D Implicit Transporter for Temporally Consistent Keypoint Discovery | [![GitHub](https://img.shields.io/github/stars/zhongcl-thu/3D-Implicit-Transporter)](https://github.com/zhongcl-thu/3D-Implicit-Transporter) | [![ResearchGate](https://img.shields.io/badge/Research-Gate-D7E7F5.svg)](https://www.researchgate.net/publication/373328882_3D_Implicit_Transporter_for_Temporally_Consistent_Keypoint_Discovery) | :heavy_minus_sign: |
| Chordal Averaging on Flag Manifolds and its Applications | [![GitHub](https://img.shields.io/github/stars/nmank/FlagAveraging)](https://github.com/nmank/FlagAveraging) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13501-b31b1b.svg)](https://arxiv.org/abs/2303.13501) | :heavy_minus_sign: |
| UniDexGrasp++: Improving Universal Dexterous Grasping via Geometry-Aware Curriculum Learning and Iterative Generalist-Specialist Learning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.00464-b31b1b.svg)](https://arxiv.org/abs/2304.00464) | :heavy_minus_sign: |
| GameFormer: Game-Theoretic Modeling and Learning of Transformer-based Interactive Prediction and Planning for Autonomous Driving | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mczhi.github.io/GameFormer/) <br /> [![GitHub](https://img.shields.io/github/stars/MCZhi/GameFormer)](https://github.com/MCZhi/GameFormer) | [![arXiv](https://img.shields.io/badge/arXiv-2303.05760-b31b1b.svg)](https://arxiv.org/abs/2303.05760) | :heavy_minus_sign: |
| PPR: Physically Plausible Reconstruction from Monocular Videos | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://gengshan-y.github.io/ppr/) <br /> [![GitHub](https://img.shields.io/github/stars/gengshan-y/ppr)](https://github.com/gengshan-y/ppr) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://gengshan-y.github.io/ppr/PPR.pdf) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Privacy, Security, Fairness, and Explainability

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Zolly: Zoom Focal Length Correctly for Perspective-Distorted Human Mesh Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wenjiawang0312.github.io/projects/zolly/) <br /> [![GitHub](https://img.shields.io/github/stars/WenjiaWang0312/Zolly)](https://github.com/WenjiaWang0312/Zolly) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13796-b31b1b.svg)](https://arxiv.org/abs/2303.13796) | :heavy_minus_sign: |
| ACLS: Adaptive and Conditional Label Smoothing for Network Calibration | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cvlab.yonsei.ac.kr/projects/ACLS/) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11911-b31b1b.svg)](https://arxiv.org/abs/2308.11911) | :heavy_minus_sign: |
| PGFed: Personalize Each Client's Global Objective for Federated Learning | [![GitHub](https://img.shields.io/github/stars/ljaiverson/pgfed)](https://github.com/ljaiverson/pgfed) | [![arXiv](https://img.shields.io/badge/arXiv-2212.01448-b31b1b.svg)](https://arxiv.org/abs/2212.01448) | :heavy_minus_sign: |
| Overcoming Bias in Pretrained Models by Manipulating the Finetuning Dataset | [![GitHub](https://img.shields.io/github/stars/princetonvisualai/overcoming-pretraining-bias)](https://github.com/princetonvisualai/overcoming-pretraining-bias) | [![arXiv](https://img.shields.io/badge/arXiv-2303.06167-b31b1b.svg)](https://arxiv.org/abs/2303.06167) <br /> [![ResearchGate](https://img.shields.io/badge/Research-Gate-D7E7F5.svg)](https://www.researchgate.net/publication/369199104_Overcoming_Bias_in_Pretrained_Models_by_Manipulating_the_Finetuning_Dataset) | :heavy_minus_sign: |
| ITI-GEN: Inclusive Text-to-Image Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://czhang0528.github.io/iti-gen) <br /> [![GitHub](https://img.shields.io/github/stars/humansensinglab/ITI-GEN)](https://github.com/humansensinglab/ITI-GEN) | [![arXiv](https://img.shields.io/badge/arXiv-2309.05569-b31b1b.svg)](https://arxiv.org/abs/2309.05569) | :heavy_minus_sign: |
| FunnyBirds: A Synthetic Vision Dataset for a Part-based Analysis of Explainable AI Methods | [![GitHub](https://img.shields.io/github/stars/visinf/funnybirds)](https://github.com/visinf/funnybirds) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06248-b31b1b.svg)](https://arxiv.org/abs/2308.06248) | :heavy_minus_sign: |
| X-VoE: Measuring eXplanatory Violation of Expectation in Physical Events | [![GitHub](https://img.shields.io/github/stars/daibopku/X-VoE)](https://github.com/daibopku/X-VoE) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10441-b31b1b.svg)](https://arxiv.org/abs/2308.10441) | :heavy_minus_sign: |
| Adaptive Testing of Computer Vision Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2212.02774-b31b1b.svg)](https://arxiv.org/abs/2212.02774) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Fairness, Privacy, Ethics, Social-good, Transparency, Accountability in Vision

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Enhancing Privacy Preservation in Federated Learning via Learning Rate Perturbation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TARGET: Federated Class-Continual Learning via Exemplar-Free Distillation | [![GitHub](https://img.shields.io/github/stars/zj-jayzhang/Federated-Class-Continual-Learning)](https://github.com/zj-jayzhang/Federated-Class-Continual-Learning) | [![arXiv](https://img.shields.io/badge/arXiv-2303.06937-b31b1b.svg)](https://arxiv.org/abs/2303.06937) | :heavy_minus_sign: |
| FACTS: First Amplify Correlations and then Slice to Discover Bias | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Computation and Data Efficient Backdoor Attacks | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Global Balanced Experts for Federated Long-Tailed Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Source-Free Domain Adaptive Human Pose Estimation | [![GitHub](https://img.shields.io/github/stars/davidpengucf/SFDAHPE)](https://github.com/davidpengucf/SFDAHPE) | [![arXiv](https://img.shields.io/badge/arXiv-2308.03202-b31b1b.svg)](https://arxiv.org/abs/2308.03202) | :heavy_minus_sign: |
| Gender Artifacts in Visual Datasets | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://princetonvisualai.github.io/gender-artifacts/) <br /> [![GitHub](https://img.shields.io/github/stars/princetonvisualai/gender-artifacts)](https://github.com/princetonvisualai/gender-artifacts) | [![arXiv](https://img.shields.io/badge/arXiv-2206.09191-b31b1b.svg)](https://arxiv.org/abs/2206.09191) | :heavy_minus_sign: |
| FRAug: Tackling Federated Learning with Non-IID Features via Representation Augmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2205.14900-b31b1b.svg)](https://arxiv.org/abs/2205.14900) | :heavy_minus_sign: |
| zPROBE: Zero Peek Robustness Checks for Federated Learning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2206.12100-b31b1b.svg)](https://arxiv.org/abs/2206.12100) | :heavy_minus_sign: |
| Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models: A Pilot Study | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| FedPD: Federated Open Set Recognition with Parameter Disentanglement | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MUter: Machine Unlearning for Adversarial Training Models | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Beyond Skin Tone: A Multidimensional Measure of Apparent Skin Color | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.05148-b31b1b.svg)](https://arxiv.org/abs/2309.05148) | :heavy_minus_sign: |
| A Multidimensional Analysis of Social Biases in Vision Transformers | [![GitHub](https://img.shields.io/github/stars/jannik-brinkmann/social-biases-in-vision-transformers)](https://github.com/jannik-brinkmann/social-biases-in-vision-transformers) | [![arXiv](https://img.shields.io/badge/arXiv-2308.01948-b31b1b.svg)](https://arxiv.org/abs/2308.01948) | :heavy_minus_sign: |
| Partition-and-Debias: Agnostic Biases Mitigation via a Mixture of Biases-Specific Experts | [![GitHub](https://img.shields.io/github/stars/Jiaxuan-Li/PnD)](https://github.com/Jiaxuan-Li/PnD) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10005-b31b1b.svg)](https://arxiv.org/abs/2308.10005) | :heavy_minus_sign: |
| Rethinking Data Distillation: Do not Overlook Calibration | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.12463-b31b1b.svg)](https://arxiv.org/abs/2307.12463) | :heavy_minus_sign: |
| Mining Bias-Target Alignment from Voronoi Cells | [![GitHub](https://img.shields.io/github/stars/renahon/mining_bias_target_alignment_from_voronoi_cells)](https://github.com/renahon/mining_bias_target_alignment_from_voronoi_cells) | [![arXiv](https://img.shields.io/badge/arXiv-2305.03691-b31b1b.svg)](https://arxiv.org/abs/2305.03691) | :heavy_minus_sign: |
| Better May not be Fairer: A Study on Subgroup Discrepancy in Image Classification | [![GitHub](https://img.shields.io/github/stars/charismaticchiu/CIFAR-B)](https://github.com/charismaticchiu/CIFAR-B) | :heavy_minus_sign: | :heavy_minus_sign: |
| GIFD: A Generative Gradient Inversion Method with Feature Domain Optimization | [![GitHub](https://img.shields.io/github/stars/ffhibnese/GIFD)](https://github.com/ffhibnese/GIFD) | [![arXiv](https://img.shields.io/badge/arXiv-2308.04699-b31b1b.svg)](https://arxiv.org/abs/2308.04699) | :heavy_minus_sign: |
| Benchmarking Algorithmic Bias in Face Recognition: An Experimental Approach using Synthetic Faces and Human Evaluation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.05441-b31b1b.svg)](https://arxiv.org/abs/2308.05441) | :heavy_minus_sign: |
| FedPerfix: Towards Partial Model Personalization of Vision Transformers in Federated Learning | [![GitHub](https://img.shields.io/github/stars/imguangyu/FedPerfix)](https://github.com/imguangyu/FedPerfix) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09160-b31b1b.svg)](https://arxiv.org/abs/2308.09160) | :heavy_minus_sign: |
| Towards Attack-Tolerant Federated Learning via Critical Parameter Analysis | [![GitHub](https://img.shields.io/github/stars/Sungwon-Han/FEDCPA)](https://github.com/Sungwon-Han/FEDCPA) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09318-b31b1b.svg)](https://arxiv.org/abs/2308.09318) | :heavy_minus_sign: |
| What can Discriminator do? Towards Box-Free Ownership Verification of Generative Adversarial Networks | [![GitHub](https://img.shields.io/github/stars/AbstractTeen/gan_ownership_verification)](https://github.com/AbstractTeen/gan_ownership_verification) | [![arXiv](https://img.shields.io/badge/arXiv-2307.15860-b31b1b.svg)](https://arxiv.org/abs/2307.15860) | :heavy_minus_sign: |
| Robust Heterogeneous Federated Learning under Data Corruption | [![GitHub](https://img.shields.io/github/stars/FangXiuwen/AugHFL)](https://github.com/FangXiuwen/AugHFL) | :heavy_minus_sign: | :heavy_minus_sign: |
| Communication-Efficient Federated Learning with Single-Step Synthetic Features Compressor for Faster Convergence | [![GitHub](https://img.shields.io/github/stars/Soptq/iccv23-3sfc)](https://github.com/Soptq/iccv23-3sfc) | [![arXiv](https://img.shields.io/badge/arXiv-2302.13562-b31b1b.svg)](https://arxiv.org/abs/2302.13562) | :heavy_minus_sign: |
| GPFL: Simultaneously Learning Global and Personalized Feature Information for Personalized Federated Learning | [![GitHub](https://img.shields.io/github/stars/TsingZ0/GPFL)](https://github.com/TsingZ0/GPFL) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10279-b31b1b.svg)](https://arxiv.org/abs/2308.10279) | :heavy_minus_sign: |
| MPCViT: Searching for Accurate and Efficient MPC-Friendly Vision Transformer with Heterogeneous Attention | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2211.13955-b31b1b.svg)](https://arxiv.org/abs/2211.13955) | :heavy_minus_sign: |
| Identification of Systematic Errors of Image Classifiers on Rare Subgroups | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.05072-b31b1b.svg)](https://arxiv.org/abs/2303.05072) | :heavy_minus_sign: |
| Adaptive Image Anonymization in the Context of Image Classification with Neural Networks | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| When do Curricula Work in Federated Learning? | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2212.12712-b31b1b.svg)](https://arxiv.org/abs/2212.12712) | :heavy_minus_sign: |
| Domain Specified Optimization for Deployment Authorization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| STPrivacy: Spatio-Temporal Privacy-Preserving Action Recognition |  | [![arXiv](https://img.shields.io/badge/arXiv-2301.03046-b31b1b.svg)](https://arxiv.org/abs/2301.03046) | :heavy_minus_sign: |
| SAL-ViT: Towards Latency Efficient Private Inference on ViT using Selective Attention Search with a Learnable Softmax Approximation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Generative Gradient Inversion without Prior | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Inspecting the Geographical Representativeness of Images from Text-to-Image Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.11080-b31b1b.svg)](https://arxiv.org/abs/2305.11080) | :heavy_minus_sign: |
| Divide and Conquer: A Two-Step Method for High Quality Face De-Identification with Model Explainability | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Exploring the Benefits of Visual Prompting in Differential Privacy | [![GitHub](https://img.shields.io/github/stars/EzzzLi/Prom-PATE)](https://github.com/EzzzLi/Prom-PATE) | [![arXiv](https://img.shields.io/badge/arXiv-2303.12247-b31b1b.svg)](https://arxiv.org/abs/2303.12247) | :heavy_minus_sign: |
| Towards Fairness-Aware Adversarial Network Pruning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| AutoReP: Automatic ReLU Replacement for Fast Private Network Inference | [![GitHub](https://img.shields.io/github/stars/HarveyP123/AutoReP)](https://github.com/HarveyP123/AutoReP) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10134-b31b1b.svg)](https://arxiv.org/abs/2308.10134) | :heavy_minus_sign: |
| Flatness-Aware Minimization for Domain Generalization | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.11108-b31b1b.svg)](https://arxiv.org/abs/2307.11108) | :heavy_minus_sign: |
| Communication-Efficient Vertical Federated Learning with Limited Overlapping Samples | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/NVIDIA/NVFlare/tree/main/research/one-shot-vfl) | [![arXiv](https://img.shields.io/badge/arXiv-2303.16270-b31b1b.svg)](https://arxiv.org/abs/2303.16270) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### First Person (Egocentric) Vision

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Multimodal Distillation for Egocentric Action Recognition | [![GitHub](https://img.shields.io/github/stars/gorjanradevski/multimodal-distillation)](https://github.com/gorjanradevski/multimodal-distillation) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07483-b31b1b.svg)](https://arxiv.org/abs/2307.07483) | :heavy_minus_sign: |
| Self-Supervised Object Detection from Egocentric Videos | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Multi-Label Affordance Mapping from Egocentric Vision | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.02120-b31b1b.svg)](https://arxiv.org/abs/2309.02120) | :heavy_minus_sign: |
| Ego-Only: Egocentric Action Detection without Exocentric Transferring | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2301.01380-b31b1b.svg)](https://arxiv.org/abs/2301.01380) | :heavy_minus_sign: |
| COPILOT: Human-Environment Collision Prediction and Localization from Egocentric Videos | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/stanford.edu/copilot) | [![arXiv](https://img.shields.io/badge/arXiv-2210.01781-b31b1b.svg)](https://arxiv.org/abs/2210.01781) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lxRTPeac8Oo) |
| EgoPCA: A New Framework for Egocentric Hand-Object Interaction Understanding | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://mvig-rhos.com/ego_pca) | [![arXiv](https://img.shields.io/badge/arXiv-2309.02423-b31b1b.svg)](https://arxiv.org/abs/2309.02423) | :heavy_minus_sign: |
| EgoVLPv2: Egocentric Video-Language Pre-Training with Fusion in the Backbone | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://shramanpramanick.github.io/EgoVLPv2/) | [![arXiv](https://img.shields.io/badge/arXiv-2307.05463-b31b1b.svg)](https://arxiv.org/abs/2307.05463) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Representation Learning

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminant Analysis | [![GitHub](https://img.shields.io/github/stars/ivalab/WDiscOOD)](https://github.com/ivalab/WDiscOOD) | [![arXiv](https://img.shields.io/badge/arXiv-2303.07543-b31b1b.svg)](https://arxiv.org/abs/2303.07543) | :heavy_minus_sign: |
| Pairwise Similarity Learning is SimPLE | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| No Fear of Classifier Biases: Neural Collapse Inspired Federated Learning with Synthetic and Fixed Classifier | [![GitHub](https://img.shields.io/github/stars/ZexiLee/ICCV-2023-FedETF)](https://github.com/ZexiLee/ICCV-2023-FedETF) | [![arXiv](https://img.shields.io/badge/arXiv-2303.10058-b31b1b.svg)](https://arxiv.org/abs/2303.10058) | :heavy_minus_sign: |
| Generalizable Neural Fields as Partially Observed Neural Processes | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.06660-b31b1b.svg)](https://arxiv.org/abs/2309.06660) | :heavy_minus_sign: |
| M2T: Masking Transformers Twice for Faster Decoding | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.07313-b31b1b.svg)](https://arxiv.org/abs/2304.07313) | :heavy_minus_sign: |
| Keep it SimPool: Who Said Supervised Transformers Suffer from Attention Deficit? | [![GitHub](https://img.shields.io/github/stars/billpsomas/simpool)](https://github.com/billpsomas/simpool) | [![arXiv](https://img.shields.io/badge/arXiv-2309.06891-b31b1b.svg)](https://arxiv.org/abs/2309.06891) | :heavy_minus_sign: |
| Improving Pixel-based MIM by Reducing Wasted Modeling Capability | [![GitHub](https://img.shields.io/github/stars/open-mmlab/mmpretrain)](https://github.com/open-mmlab/mmpretrain) | [![arXiv](https://img.shields.io/badge/arXiv-2308.00261-b31b1b.svg)](https://arxiv.org/abs/2308.00261) | :heavy_minus_sign: |
| Learning Image-Adaptive Codebooks for Class-Agnostic Image Restoration | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.06513-b31b1b.svg)](https://arxiv.org/abs/2306.06513) | :heavy_minus_sign: |
| Quality Diversity for Visual Pre-Training | [![GitHub](https://img.shields.io/github/stars/ruchikachavhan/quality-diversity-pretraining)](https://github.com/ruchikachavhan/quality-diversity-pretraining) | :heavy_minus_sign: | :heavy_minus_sign: |
| Subclass-Balancing Contrastive Learning for Long-Tailed Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.15925-b31b1b.svg)](https://arxiv.org/abs/2306.15925) | :heavy_minus_sign: |
| Mastering Spatial Graph Prediction of Road Networks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2210.00828-b31b1b.svg)](https://arxiv.org/abs/2210.00828) | :heavy_minus_sign: |
| Poincaré ResNet | [![GitHub](https://img.shields.io/github/stars/maxvanspengler/poincare-resnet)](https://github.com/maxvanspengler/poincare-resnet) | [![arXiv](https://img.shields.io/badge/arXiv-2303.14027-b31b1b.svg)](https://arxiv.org/abs/2303.14027) | :heavy_minus_sign: |
| Exploring Model Transferability through the Lens of Potential Energy | [![GitHub](https://img.shields.io/github/stars/lixiaotong97/PED)](https://github.com/lixiaotong97/PED) | [![arXiv](https://img.shields.io/badge/arXiv-2308.15074-b31b1b.svg)](https://arxiv.org/abs/2308.15074) | :heavy_minus_sign: |
| Improving CLIP Fine-Tuning Performance | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Unsupervised Manifold Linearizing and Clustering |  | [![arXiv](https://img.shields.io/badge/arXiv-2301.01805-b31b1b.svg)](https://arxiv.org/abs/2301.01805) | :heavy_minus_sign: |
| Generalized Sum Pooling for Metric Learning | [![GitHub](https://img.shields.io/github/stars/yetigurbuz/generalized-sum-pooling)](https://github.com/yetigurbuz/generalized-sum-pooling) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09228-b31b1b.svg)](https://arxiv.org/abs/2308.09228) | :heavy_minus_sign: |
| Partition Speeds Up Learning Implicit Neural Representations based on Exponential-Increase Hypothesis | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| The Effectiveness of MAE Pre-Pretraining for Billion-Scale Pretraining | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.13496-b31b1b.svg)](https://arxiv.org/abs/2303.13496) | :heavy_minus_sign: |
| Token-Label Alignment for Vision Transformers | [![GitHub](https://img.shields.io/github/stars/Euphoria16/TL-Align)](https://github.com/Euphoria16/TL-Align) | [![arXiv](https://img.shields.io/badge/arXiv-2210.06455-b31b1b.svg)](https://arxiv.org/abs/2210.06455) | :heavy_minus_sign: |
| Efficiently Robustify Pre-Trained Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.07499-b31b1b.svg)](https://arxiv.org/abs/2309.07499) | :heavy_minus_sign: |
| OFVL-MS: Once for Visual Localization Across Multiple Indoor Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/mooncake199809/UFVL-Net/tree/main/configs/ofvl_ms) <br /> [![GitHub](https://img.shields.io/github/stars/mooncake199809/UFVL-Net)](https://github.com/mooncake199809/UFVL-Net) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11928-b31b1b.svg)](https://arxiv.org/abs/2308.11928) | :heavy_minus_sign: |
| Feature Prediction Diffusion Model for Video Anomaly Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Joint Implicit Neural Representation for High-Fidelity and Compact Vector Fonts | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| How Far Pre-Trained Models are from Neural Collapse on the Target Dataset Informs their Transferability | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| OPERA: Omni-Supervised Representation Learning with Hierarchical Supervisions | [![GitHub](https://img.shields.io/github/stars/wangck20/OPERA)](https://github.com/wangck20/OPERA) | [![arXiv](https://img.shields.io/badge/arXiv-2210.05557-b31b1b.svg)](https://arxiv.org/abs/2210.05557) | :heavy_minus_sign: |
| Perceptual Grouping in Contrastive Vision-Language Models | [![GitHub](https://img.shields.io/github/stars/kahnchana/clippy)](https://github.com/kahnchana/clippy) | [![arXiv](https://img.shields.io/badge/arXiv-2210.09996-b31b1b.svg)](https://arxiv.org/abs/2210.09996) | :heavy_minus_sign: |
| Fully Attentional Networks with Self-Emerging Token Labeling | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Instance and Category Supervision are Alternate Learners for Continual Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| SkeletonMAE: Graph-based Masked Autoencoder for Skeleton Sequence Pre-Training | [![GitHub](https://img.shields.io/github/stars/HongYan1123/SkeletonMAE)](https://github.com/HongYan1123/SkeletonMAE) | [![arXiv](https://img.shields.io/badge/arXiv-2307.08476-b31b1b.svg)](https://arxiv.org/abs/2307.08476) | :heavy_minus_sign: |
| Motion-Guided Masking for Spatiotemporal Representation Learning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.12962-b31b1b.svg)](https://arxiv.org/abs/2308.12962) <br /> [![Amazon Science](https://img.shields.io/badge/amazon-science-FE9901.svg)](https://www.amazon.science/publications/motion-guided-masking-for-spatiotemporal-representation-learning) | :heavy_minus_sign: |
| Data Augmented Flatness-Aware Gradient Projection for Continual Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Take-a-Photo: 3D-to-2D Generative Pre-Training of Point Cloud Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://tap.ivg-research.xyz/) <br /> [![GitHub](https://img.shields.io/github/stars/wangzy22/TAP)](https://github.com/wangzy22/TAP) | [![arXiv](https://img.shields.io/badge/arXiv-2307.14971-b31b1b.svg)](https://arxiv.org/abs/2307.14971) | :heavy_minus_sign: |
| BiViT: Extremely Compressed Binary Vision Transformers | [![GitHub](https://img.shields.io/github/stars/ThisisBillhe/BiViT)](https://github.com/ThisisBillhe/BiViT) | [![arXiv](https://img.shields.io/badge/arXiv-2211.07091-b31b1b.svg)](https://arxiv.org/abs/2211.07091) | :heavy_minus_sign: |
| Spatio-Temporal Crop Aggregation for Video Representation Learning | [![GitHub](https://img.shields.io/github/stars/Separius/SCALE)](https://github.com/Separius/SCALE) | [![arXiv](https://img.shields.io/badge/arXiv-2211.17042-b31b1b.svg)](https://arxiv.org/abs/2211.17042) | :heavy_minus_sign: |
| Hierarchical Visual Primitive Experts for Compositional Zero-Shot Learning | [![GitHub](https://img.shields.io/github/stars/HanjaeKim98/CoT)](https://github.com/HanjaeKim98/CoT) | [![arXiv](https://img.shields.io/badge/arXiv-2308.04016-b31b1b.svg)](https://arxiv.org/abs/2308.04016) | :heavy_minus_sign: |
| Semantic Information in Contrastive Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Cross-Domain Product Representation Learning for Rich-Content E-Commerce | [![GitHub](https://img.shields.io/github/stars/adxcreative/COPE)](https://github.com/adxcreative/COPE) | [![arXiv](https://img.shields.io/badge/arXiv-2308.05550-b31b1b.svg)](https://arxiv.org/abs/2308.05550) | :heavy_minus_sign: |
| Contrastive Continuity on Augmentation Stability Rehearsal for Continual Self-Supervised Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| HybridAugment++: Unified Frequency Spectra Perturbations for Model Robustness | [![GitHub](https://img.shields.io/github/stars/MKYucel/hybrid_augment)](https://github.com/MKYucel/hybrid_augment) | [![arXiv](https://img.shields.io/badge/arXiv-2307.11823-b31b1b.svg)](https://arxiv.org/abs/2307.11823) | :heavy_minus_sign: |
| Unleashing Text-to-Image Diffusion Models for Visual Perception | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://vpd.ivg-research.xyz/) <br /> [![GitHub](https://img.shields.io/github/stars/wl-zhao/VPD)](https://github.com/wl-zhao/VPD) | [![arXiv](https://img.shields.io/badge/arXiv-2303.02153-b31b1b.svg)](https://arxiv.org/abs/2303.02153) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Deep Learning Architectures

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Efficient Controllable Multi-Task Architectures | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.11744-b31b1b.svg)](https://arxiv.org/abs/2308.11744) | :heavy_minus_sign: |
| ParCNetV2: Oversized Kernel with Enhanced Attention | [![GitHub](https://img.shields.io/github/stars/XuRuihan/ParCNetV2)](https://github.com/XuRuihan/ParCNetV2) | [![arXiv](https://img.shields.io/badge/arXiv-2211.07157-b31b1b.svg)](https://arxiv.org/abs/2211.07157) | :heavy_minus_sign: |
| Unleashing the Power of Gradient Signal-to-Noise Ratio for Zero-Shot NAS | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MMST-ViT: Climate Change-Aware Crop Yield Prediction via Multi-Modal Spatial-Temporal Vision Transformer | [![GitHub](https://img.shields.io/github/stars/fudong03/MMST-ViT)](https://github.com/fudong03/MMST-ViT) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://drive.google.com/file/d/1xc_8KkOxVUVsHUiz9Vgv1nqqOa2O_t-2/view) | :heavy_minus_sign: |
| FastViT: A Fast Hybrid Vision Transformer using Structural Reparameterization | [![GitHub](https://img.shields.io/github/stars/apple/ml-fastvit)](https://github.com/apple/ml-fastvit) | [![arXiv](https://img.shields.io/badge/arXiv-2303.14189-b31b1b.svg)](https://arxiv.org/abs/2303.14189) | :heavy_minus_sign: |
| IIEU: Rethinking Neural Feature Activation from Decision-Making | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Scratching Visual Transformer's Back with Uniform Attention | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2210.08457-b31b1b.svg)](https://arxiv.org/abs/2210.08457) | :heavy_minus_sign: |
| SpaceEvo: Hardware-Friendly Search Space Design for Efficient INT8 Inference | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.08308-b31b1b.svg)](https://arxiv.org/abs/2303.08308) | :heavy_minus_sign: |
| ElasticViT: Conflict-Aware Supernet Training for Deploying Fast Vision Transformer on Diverse Mobile Devices | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.09730-b31b1b.svg)](https://arxiv.org/abs/2303.09730) | :heavy_minus_sign: |
| Gramian Attention Heads are Strong yet Efficient Vision Learners | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| EfficientTrain: Exploring Generalized Curriculum Learning for Training Visual Backbones | [![GitHub](https://img.shields.io/github/stars/LeapLabTHU/EfficientTrain)](https://github.com/LeapLabTHU/EfficientTrain) | [![arXiv](https://img.shields.io/badge/arXiv-2211.09703-b31b1b.svg)](https://arxiv.org/abs/2211.09703) | :heavy_minus_sign: |
| Ord2Seq: Regarding Ordinal Regression as Label Sequence Prediction | [![GitHub](https://img.shields.io/github/stars/wjh892521292/Ord2Seq)](https://github.com/wjh892521292/Ord2Seq) | [![arXiv](https://img.shields.io/badge/arXiv-2307.09004-b31b1b.svg)](https://arxiv.org/abs/2307.09004) | :heavy_minus_sign: |
| Unified Data-Free Compression: Pruning and Quantization without Fine-Tuning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.07209-b31b1b.svg)](https://arxiv.org/abs/2308.07209) | :heavy_minus_sign: |
| LaPE: Layer-Adaptive Position Embedding for Vision Transformers with Independent Layer Normalization | [![GitHub](https://img.shields.io/github/stars/Ingrid725/LaPE)](https://github.com/Ingrid725/LaPE) | [![arXiv](https://img.shields.io/badge/arXiv-2212.05262-b31b1b.svg)](https://arxiv.org/abs/2212.05262) | :heavy_minus_sign: |
| Exemplar-Free Continual Transformer with Convolutions | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cvir.github.io/projects/contracon) <br /> [![GitHub](https://img.shields.io/github/stars/CVIR/contracon)](https://github.com/CVIR/contracon) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11357-b31b1b.svg)](https://arxiv.org/abs/2308.11357) | :heavy_minus_sign: |
| Building Vision Transformers with Hierarchy Aware Feature Aggregation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| ShiftNAS: Improving One-Shot NAS via Probability Shift | [![GitHub](https://img.shields.io/github/stars/bestfleer/ShiftNAS)](https://github.com/bestfleer/ShiftNAS) | [![arXiv](https://img.shields.io/badge/arXiv-2307.08300-b31b1b.svg)](https://arxiv.org/abs/2307.08300) | :heavy_minus_sign: |
| DarSwin: Distortion Aware Radial Swin Transformer | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lvsn.github.io/darswin/) | [![arXiv](https://img.shields.io/badge/arXiv-2304.09691-b31b1b.svg)](https://arxiv.org/abs/2304.09691) | :heavy_minus_sign: |
| ROME: Robustifying Memory-Efficient NAS via Topology Disentanglement and Gradient Accumulation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2011.11233-b31b1b.svg)](https://arxiv.org/abs/2011.11233) | :heavy_minus_sign: |
| FDViT: Improve the Hierarchical Architecture of Vision Transformer | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| FLatten Transformer: Vision Transformer using Focused Linear Attention | [![GitHub](https://img.shields.io/github/stars/LeapLabTHU/FLatten-Transformer)](https://github.com/LeapLabTHU/FLatten-Transformer) | [![arXiv](https://img.shields.io/badge/arXiv-2308.00442-b31b1b.svg)](https://arxiv.org/abs/2308.00442) | :heavy_minus_sign: |
| MixPath: A Unified Approach for One-Shot Neural Architecture Search | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2001.05887-b31b1b.svg)](https://arxiv.org/abs/2001.05887) | :heavy_minus_sign: |
| SSF: Accelerating Training of Spiking Neural Networks with Stabilized Spiking Flow | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Dynamic Perceiver for Efficient Visual Recognition | [![GitHub](https://img.shields.io/github/stars/LeapLabTHU/Dynamic_Perceiver)](https://github.com/LeapLabTHU/Dynamic_Perceiver) | [![arXiv](https://img.shields.io/badge/arXiv-2306.11248-b31b1b.svg)](https://arxiv.org/abs/2306.11248) | :heavy_minus_sign: |
| SG-Former: Self-Guided Transformer with Evolving Token Reallocation | [![GitHub](https://img.shields.io/github/stars/OliverRensu/SG-Former)](https://github.com/OliverRensu/SG-Former) | [![arXiv](https://img.shields.io/badge/arXiv-2308.12216-b31b1b.svg)](https://arxiv.org/abs/2308.12216) | :heavy_minus_sign: |
| Scale-Aware Modulation Meet Transformer | [![GitHub](https://img.shields.io/github/stars/AFeng-x/SMT)](https://github.com/AFeng-x/SMT) | [![arXiv](https://img.shields.io/badge/arXiv-2307.08579-b31b1b.svg)](https://arxiv.org/abs/2307.08579) | :heavy_minus_sign: |
| Learning to Upsample by Learning to Sample | [![GitHub](https://img.shields.io/github/stars/tiny-smart/dysample)](https://github.com/tiny-smart/dysample) | [![arXiv](https://img.shields.io/badge/arXiv-2308.15085-b31b1b.svg)](https://arxiv.org/abs/2308.15085) | :heavy_minus_sign: |
| GET: Group Event Transformer for Event-based Vision | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Adaptive Frequency Filters as Efficient Global Token Mixers | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/microsoft/TokenMixers/tree/main/Adaptive%20Frequency%20Filters) | [![arXiv](https://img.shields.io/badge/arXiv-2307.14008-b31b1b.svg)](https://arxiv.org/abs/2307.14008) | :heavy_minus_sign: |
| Fcaformer: Forward Cross Attention in Hybrid Vision Transformer | [![GitHub](https://img.shields.io/github/stars/hkzhang-git/FcaFormer)](https://github.com/hkzhang-git/FcaFormer) | [![arXiv](https://img.shields.io/badge/arXiv-2211.07198-b31b1b.svg)](https://arxiv.org/abs/2211.07198) | :heavy_minus_sign: |
| Dynamic Snake Convolution based on Topological Geometric Constraints for Tubular Structure Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yaoleiqi.github.io/pub_homepage/2023_ICCV/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/YaoleiQi/DSCNet)](https://github.com/YaoleiQi/DSCNet) | [![arXiv](https://img.shields.io/badge/arXiv-2307.08388-b31b1b.svg)](https://arxiv.org/abs/2307.08388) | :heavy_minus_sign: |
| Sentence Attention Blocks for Answer Grounding | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MST-Compression: Compressing and Accelerating Binary Neural Networks with Minimum Spanning Tree | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.13735-b31b1b.svg)](https://arxiv.org/abs/2308.13735) | :heavy_minus_sign: |
| EGformer: Equirectangular Geometry-biased Transformer for 360 Depth Estimation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.07803-b31b1b.svg)](https://arxiv.org/abs/2304.07803) | :heavy_minus_sign: |
| SPANet: Frequency-Balancing Token Mixer using Spectral Pooling Aggregation Modulation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://doranlyong.github.io/projects/spanet/) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11568-b31b1b.svg)](https://arxiv.org/abs/2308.11568) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wEVuA9-jv00) |
| ModelGiF: Gradient Fields for Model Functional Distance | [![GitHub](https://img.shields.io/github/stars/zju-vipa/modelgif)](https://github.com/zju-vipa/modelgif) | :heavy_minus_sign: | :heavy_minus_sign: |
| ClusT3: Information Invariant Test-Time Training | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Cumulative Spatial Knowledge Distillation for Vision Transformers | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.08500-b31b1b.svg)](https://arxiv.org/abs/2307.08500) | :heavy_minus_sign: |
| Luminance-Aware Color Transform for Multiple Exposure Correction | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Towards Memory- and Time-Efficient Backpropagation for Training Spiking Neural Networks | [![GitHub](https://img.shields.io/github/stars/qymeng94/SLTT)](https://github.com/qymeng94/SLTT) | [![arXiv](https://img.shields.io/badge/arXiv-2302.14311-b31b1b.svg)](https://arxiv.org/abs/2302.14311) | :heavy_minus_sign: |
| Domain Generalization Guided by Gradient Signal to Noise Ratio of Parameters | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| DOT: A Distillation-Oriented Trainer | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.08436-b31b1b.svg)](https://arxiv.org/abs/2307.08436) | :heavy_minus_sign: |
| Extensible and Efficient Proxy for Neural Architecture Search | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Learning to Transform for Generalizable Instance-Wise Invariance | [![GitHub](https://img.shields.io/github/stars/sutkarsh/flow_inv)](https://github.com/sutkarsh/flow_inv) | :heavy_minus_sign: | :heavy_minus_sign: |
| Convolutional Networks with Oriented 1D Kernels | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Recognition: Detection

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Random Boxes are Open-World Object Detectors | [![GitHub](https://img.shields.io/github/stars/scuwyh2000/RandBox)](https://github.com/scuwyh2000/RandBox) | [![arXiv](https://img.shields.io/badge/arXiv-2307.08249-b31b1b.svg)](https://arxiv.org/abs/2307.08249) | :heavy_minus_sign: |
| Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection | [![GitHub](https://img.shields.io/github/stars/hustvl/MIMDet)](https://github.com/hustvl/MIMDet) | [![arXiv](https://img.shields.io/badge/arXiv-2204.02964-b31b1b.svg)](https://arxiv.org/abs/2204.02964) | :heavy_minus_sign: |
| CoIn: Contrastive Instance Feature Mining for Outdoor 3D Object Detection with Very Limited Annotations | [![GitHub](https://img.shields.io/github/stars/xmuqimingxia/CoIn)](https://github.com/xmuqimingxia/CoIn) | :heavy_minus_sign: | :heavy_minus_sign: |
| A Dynamic Dual-Processing Object Detection Framework Inspired by the Brain's Recognition Mechanism | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Anchor-Intermediate Detector: Decoupling and Coupling Bounding Boxes for Accurate Object Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Inter-Realization Channels: Unsupervised Anomaly Detection Beyond One-Class Classification | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Deep Equilibrium Object Detection | [![GitHub](https://img.shields.io/github/stars/MCG-NJU/DEQDet)](https://github.com/MCG-NJU/DEQDet) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09564-b31b1b.svg)](https://arxiv.org/abs/2308.09564) | :heavy_minus_sign: |
| RecursiveDet: End-to-End Region-based Recursive Object Detection | [![GitHub](https://img.shields.io/github/stars/bravezzzzzz/RecursiveDet)](https://github.com/bravezzzzzz/RecursiveDet) | [![arXiv](https://img.shields.io/badge/arXiv-2307.13619-b31b1b.svg)](https://arxiv.org/abs/2307.13619) | :heavy_minus_sign: |
| Small Object Detection via Coarse-to-Fine Proposal Generation and Imitation Learning | [![GitHub](https://img.shields.io/github/stars/shaunyuan22/CFINet)](https://github.com/shaunyuan22/CFINet) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09534-b31b1b.svg)](https://arxiv.org/abs/2308.09534) |  |
| ASAG: Building Strong One-Decoder-Layer Sparse Detectors via Adaptive Sparse Anchor Generation | [![GitHub](https://img.shields.io/github/stars/iSEE-Laboratory/ASAG)](https://github.com/iSEE-Laboratory/ASAG) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09242-b31b1b.svg)](https://arxiv.org/abs/2308.09242) | :heavy_minus_sign: |
| COCO-O: A Benchmark for Object Detectors under Natural Distribution Shifts | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/alibaba/easyrobust/tree/main/benchmarks/coco_o) <br /> [![GitHub](https://img.shields.io/github/stars/alibaba/easyrobust)](https://github.com/alibaba/easyrobust) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12730-b31b1b.svg)](https://arxiv.org/abs/2307.12730) | :heavy_minus_sign: |
| Generative Prompt Model for Weakly Supervised Object Localization | [![GitHub](https://img.shields.io/github/stars/callsys/GenPromp)](https://github.com/callsys/GenPromp) | [![arXiv](https://img.shields.io/badge/arXiv-2307.09756-b31b1b.svg)](https://arxiv.org/abs/2307.09756) | :heavy_minus_sign: |
| UniKD: Universal Knowledge Distillation for Mimicking Homogeneous or Heterogeneous Object Detectors | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| PNI: Industrial Anomaly Detection using Position and Neighborhood Information | [![GitHub](https://img.shields.io/github/stars/wogur110/PNI_Anomaly_Detection)](https://github.com/wogur110/PNI_Anomaly_Detection) | [![arXiv](https://img.shields.io/badge/arXiv-2211.12634-b31b1b.svg)](https://arxiv.org/abs/2211.12634) | :heavy_minus_sign: |
| Masked Autoencoders are Stronger Knowledge Distillers | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| GPA-3D: Geometry-Aware Prototype Alignment for Unsupervised Domain Adaptive 3D Object Detection from Point Clouds | [![GitHub](https://img.shields.io/github/stars/Liz66666/GPA3D)](https://github.com/Liz66666/GPA3D) | [![arXiv](https://img.shields.io/badge/arXiv-2308.08140-b31b1b.svg)](https://arxiv.org/abs/2308.08140) | :heavy_minus_sign: |
| ADNet: Lane Shape Prediction via Anchor Decomposition | [![GitHub](https://img.shields.io/github/stars/Sephirex-X/ADNet)](https://github.com/Sephirex-X/ADNet) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10481-b31b1b.svg)](https://arxiv.org/abs/2308.10481) | :heavy_minus_sign: |
| Periodically Exchange Teacher-Student for Source-Free Object Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Towards Fair and Comprehensive Comparisons for Image-based 3D Object Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Monocular 3D Object Detection with Bounding Box Denoising in 3D by Perceiver | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.01289-b31b1b.svg)](https://arxiv.org/abs/2304.01289) | :heavy_minus_sign: |
| Template-Guided Hierarchical Feature Restoration for Anomaly Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| ALWOD: Active Learning for Weakly-Supervised Object Detection | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.07914-b31b1b.svg)](https://arxiv.org/abs/2309.07914) | :heavy_minus_sign: |
| ProtoFL: Unsupervised Federated Learning via Prototypical Distillation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.12450-b31b1b.svg)](https://arxiv.org/abs/2307.12450) | :heavy_minus_sign: |
| Efficient Adaptive Human-Object Interaction Detection with Concept-Guided Memory | [![GitHub](https://img.shields.io/github/stars/ltttpku/ADA-CM)](https://github.com/ltttpku/ADA-CM) | [![arXiv](https://img.shields.io/badge/arXiv-2309.03696-b31b1b.svg)](https://arxiv.org/abs/2309.03696) | :heavy_minus_sign: |
| Detection Transformer with Stable Matching | [![GitHub](https://img.shields.io/github/stars/IDEA-Research/Stable-DINO)](https://github.com/IDEA-Research/Stable-DINO) | [![arXiv](https://img.shields.io/badge/arXiv-2304.04742-b31b1b.svg)](https://arxiv.org/abs/2304.04742) | :heavy_minus_sign: |
| Distilling DETR with Visual-Linguistic Knowledge for Open-Vocabulary Object Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Anomaly Detection Under Distribution Shift | [![GitHub](https://img.shields.io/github/stars/mala-lab/ADShift)](https://github.com/mala-lab/ADShift) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13845-b31b1b.svg)](https://arxiv.org/abs/2303.13845) | :heavy_minus_sign: |
| Detecting Objects with Context-Likelihood Graphs and Graph Refinement | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2212.12395-b31b1b.svg)](https://arxiv.org/abs/2212.12395) | :heavy_minus_sign: |
| Unsupervised Object Localization with Representer Point Selection | [![GitHub](https://img.shields.io/github/stars/yeonghwansong/UOLwRPS)](https://github.com/yeonghwansong/UOLwRPS) | [![arXiv](https://img.shields.io/badge/arXiv-2309.04172-b31b1b.svg)](https://arxiv.org/abs/2309.04172) | :heavy_minus_sign: |
| DETR does not Need Multi-Scale or Locality Design | [![GitHub](https://img.shields.io/github/stars/impiga/Plain-DETR)](https://github.com/impiga/Plain-DETR) | [![arXiv](https://img.shields.io/badge/arXiv-2308.01904-b31b1b.svg)](https://arxiv.org/abs/2308.01904) | :heavy_minus_sign: |
| Deep Directly-Trained Spiking Neural Networks for Object Detection | [![GitHub](https://img.shields.io/github/stars/BICLab/EMS-YOLO)](https://github.com/BICLab/EMS-YOLO) | [![arXiv](https://img.shields.io/badge/arXiv-2307.11411-b31b1b.svg)](https://arxiv.org/abs/2307.11411) | :heavy_minus_sign: |
| GACE: Geometry Aware Confidence Enhancement for Black-Box 3D Object Detectors on LiDAR-Data | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| StageInteractor: Query-based Object Detector with Cross-Stage Interaction | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.04978-b31b1b.svg)](https://arxiv.org/abs/2304.04978) | :heavy_minus_sign: |
| Adaptive Rotated Convolution for Rotated Object Detection | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2303.07820-b31b1b.svg)](https://arxiv.org/abs/2303.07820) | :heavy_minus_sign: |
| Decoupled DETR: Spatially Disentangling Localization and Classification for Improved End-to-End Object Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Exploring Transformers for Open-World Instance Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.04206-b31b1b.svg)](https://arxiv.org/abs/2308.04206) | :heavy_minus_sign: |
| DDG-Net: Discriminability-Driven Graph Network for Weakly-Supervised Temporal Action Localization | [![GitHub](https://img.shields.io/github/stars/XiaojunTang22/ICCV2023-DDGNet)](https://github.com/XiaojunTang22/ICCV2023-DDGNet) | [![arXiv](https://img.shields.io/badge/arXiv-2307.16415-b31b1b.svg)](https://arxiv.org/abs/2307.16415) | :heavy_minus_sign: |
| Group DETR: Fast DETR Training with Group-Wise One-to-Many Assignment | [![GitHub](https://img.shields.io/github/stars/Atten4Vis/GroupDETR)](https://github.com/Atten4Vis/GroupDETR) | [![arXiv](https://img.shields.io/badge/arXiv-2207.13085-b31b1b.svg)](https://arxiv.org/abs/2207.13085) | :heavy_minus_sign: |
| Category-Aware Allocation Transformer for Weakly Supervised Object Localization | [![GitHub](https://img.shields.io/github/stars/zhiweichen0012/CATR)](https://github.com/zhiweichen0012/CATR) | :heavy_minus_sign: | :heavy_minus_sign: |
| The Devil is in the Crack Orientation: A New Perspective for Crack Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Clusterformer: Cluster-based Transformer for 3D Object Detection in Point Clouds | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Less is more: Focus Attention for Efficient DETR | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/huawei-noah/noah-research/tree/master/Focus-DETR) <br /> [![Gitee Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://gitee.com/mindspore/models/tree/master/research/cv/Focus-DETR) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12612-b31b1b.svg)](https://arxiv.org/abs/2307.12612) |  |
| DFA3D: 3D Deformable Attention For 2D-to-3D Feature Lifting |  |  |  |
| Multi-Label Self-Supervised Learning with Scene Images |  |  |  |
| Cascade-DETR: Delving into High-Quality Universal Object Detection |  |  |  |
| Representation Disparity-Aware Distillation for 3D Object Detection |  |  |  |
| FeatEnHancer: Enhancing Hierarchical Features for Object Detection and Beyond Under Low-Light Vision |  |  |  |
| DetZero: Rethinking Offboard 3D Object Detection with Long-Term Sequential Point Clouds |  |  |  |
| DETRs with Collaborative Hybrid Assignments Training |  |  |  |
| Open-Vocabulary Object Detection with an Open Corpus |  |  |  |
| SparseDet: Improving Sparsely Annotated Object Detection with Pseudo-Positive Mining |  |  |  |
| Unsupervised Surface Anomaly Detection with Diffusion Probabilistic Model |  |  |  |
| UniTR: A Unified and Efficient Multi-Modal Transformer for Bird's-Eye-View Representation |  |  |  |
| Focus the Discrepancy: Intra- and Inter-Correlation Learning for Image Anomaly Detection |  |  |  |
| MonoNeRD: NeRF-Like Representations for Monocular 3D Object Detection |  |  |  |
| Integrally Migrating Pre-Trained Transformer Encoder-Decoders for Visual Object Detection | [![GitHub](https://img.shields.io/github/stars/LiewFeng/imTED)](https://github.com/LiewFeng/imTED) | [![arXiv](https://img.shields.io/badge/arXiv-2205.09613-b31b1b.svg)](https://arxiv.org/abs/2205.09613) | :heavy_minus_sign: |
| Generating Dynamic Kernels via Transformers for Lane Detection |  |  |  |
| Meta-ZSDETR: Zero-Shot DETR with Meta-Learning |  |  |  |
| Spatial Self-Distillation for Object Detection with Inaccurate Bounding Boxes |  |  |  |
| AlignDet: Aligning Pre-Training and Fine-Tuning in Object Detection |  |  |  |
| MULLER: Multilayer Laplacian Resizer for Vision |  |  |  |
| Unilaterally Aggregated Contrastive Learning with Hierarchical Augmentation for Anomaly Detection |  |  |  |
| DETRDistill: A Universal Knowledge Distillation Framework for DETR-Families |  |  |  |
| Delving into Motion-Aware Matching for Monocular 3D Object Tracking |  |  |  |
| FB-BEV: BEV Representation from Forward-Backward View Transformations |  |  |  |
| Learning from Noisy Data for Semi-Supervised 3D Object Detection |  |  |  |
| Boosting Long-Tailed Object Detection via Step-Wise Learning on Smooth-Tail Data |  |  |  |
| Objects do not Disappear: Video Object Detection by Single-Frame Object Location Anticipation |  |  |  |
| Unified Visual Relationship Detection with Vision and Language Models |  |  |  |
| Universal Domain Adaptation via Compressive Attention Matching |  |  |  |
| Unsupervised Domain Adaptive Detection with Network Stability Analysis |  |  |  |
| ImGeoNet: Image-Induced Geometry-Aware Voxel Representation for Multi-View 3D Object Detection |  |  |  |
| Cyclic-Bootstrap Labeling for Weakly Supervised Object Detection |  |  |  |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Image and Video Synthesis

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model | [![GitHub](https://img.shields.io/github/stars/vvictoryuki/FreeDoM)](https://github.com/vvictoryuki/FreeDoM) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09833-b31b1b.svg)](https://arxiv.org/abs/2303.09833) | :heavy_minus_sign: |
| BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion | [![GitHub](https://img.shields.io/github/stars/showlab/BoxDiff)](https://github.com/showlab/BoxDiff) | [![arXiv](https://img.shields.io/badge/arXiv-2307.10816-b31b1b.svg)](https://arxiv.org/abs/2307.10816) | :heavy_minus_sign: |
| LayoutDiffusion: Improving Graphic Layout Generation by Discrete Diffusion Probabilistic Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/microsoft/LayoutGeneration/tree/main/LayoutDiffusion) <br /> [![GitHub](https://img.shields.io/github/stars/microsoft/LayoutGeneration)](https://github.com/microsoft/LayoutGeneration) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11589-b31b1b.svg)](https://arxiv.org/abs/2303.11589) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision and Audio

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Recognition, Segmentation, and Shape Analysis

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Generative AI

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Simulating Fluids in Real-World Still Images | [![GitHub](https://img.shields.io/github/stars/simon3dv/SLR-SFS)](https://github.com/simon3dv/SLR-SFS) | [![arXiv](https://img.shields.io/badge/arXiv-2204.11335-b31b1b.svg)](https://arxiv.org/abs/2204.11335) | :heavy_minus_sign: |
| FateZero: Fusing Attentions for Zero-Shot Text-based Video Editing | [![GitHub](https://img.shields.io/github/stars/ChenyangQiQi/FateZero)](https://github.com/ChenyangQiQi/FateZero) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09535-b31b1b.svg)](https://arxiv.org/abs/2303.09535) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Humans, 3D Modeling, and Driving

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Low-Level Vision and Theory

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| DDFM: Denoising Diffusion Model for Multi-Modality Image Fusion | [![GitHub](https://img.shields.io/github/stars/Zhaozixiang1228/MMIF-DDFM)](https://github.com/Zhaozixiang1228/MMIF-DDFM) | [![arXiv](https://img.shields.io/badge/arXiv-2303.06840-b31b1b.svg)](https://arxiv.org/abs/2303.06840) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Navigation and Autonomous Driving

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### 3D from a Single Image and Shape-from-X

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Motion Estimation, Matching and Tracking

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Action and Event Understanding

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Computational Imaging

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Embodied Vision: Active Agents; Simulation

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Recognition: Retrieval

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Transfer, Low-Shot, Continual, Long-Tail Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Low-Level and Physics-based Vision

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| High-Resolution Document Shadow Removal via a Large-Scale Real-World Dataset and a Frequency-Aware Shadow Erasing Net | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cxh-research.github.io/DocShadow-SD7K/) <br /> [![GitHub](https://img.shields.io/github/stars/CXH-Research/DocShadow-SD7K)](https://github.com/CXH-Research/DocShadow-SD7K) | [![arXiv](https://img.shields.io/badge/arXiv-2308.14221-b31b1b.svg)](https://arxiv.org/abs/2308.14221) | :heavy_minus_sign: |
| Iterative Soft Shrinkage Learning for Efficient Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/Jiamian-Wang/Iterative-Soft-Shrinkage-SR)](https://github.com/Jiamian-Wang/Iterative-Soft-Shrinkage-SR) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09650-b31b1b.svg)](https://arxiv.org/abs/2303.09650) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Computer Vision Theory

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Femtodet: An Object Detection Baseline for Energy Versus Performance Tradeoffs | [![GitHub](https://img.shields.io/github/stars/yh-pengtu/FemtoDet)](https://github.com/yh-pengtu/FemtoDet) | [![arXiv](https://img.shields.io/badge/arXiv-2301.06719-b31b1b.svg)](https://arxiv.org/abs/2301.06719) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Video Analysis and Understanding

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Object Pose Estimation and Tracking

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### 3D Shape Modeling and Processing

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Human Pose/Shape Estimation

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Transfer, Low-Shot, and Continual Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Self-, Semi-, and Unsupervised Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Self-, Semi-, Meta-, Unsupervised Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Photogrammetry and Remote Sensing

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Efficient and Scalable Vision

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| AdaNIC: Towards Practical Neural Image Compression via Dynamic Transform Routing | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Rethinking Vision Transformers for MobileNet Size and Speed | [![GitHub](https://img.shields.io/github/stars/snap-research/EfficientFormer)](https://github.com/snap-research/EfficientFormer) | [![arXiv](https://img.shields.io/badge/arXiv-2212.08059-b31b1b.svg)](https://arxiv.org/abs/2212.08059) | :heavy_minus_sign: |
| DELFlow: Dense Efficient Learning of Scene Flow for Large-Scale Point Clouds | [![GitHub](https://img.shields.io/github/stars/IRMVLab/DELFlow)](https://github.com/IRMVLab/DELFlow) | [![arXiv](https://img.shields.io/badge/arXiv-2308.04383-b31b1b.svg)](https://arxiv.org/abs/2308.04383) | :heavy_minus_sign: |
| Eventful Transformers: Leveraging Temporal Redundancy in Vision Transformers | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.13494-b31b1b.svg)](https://arxiv.org/abs/2308.13494) | :heavy_minus_sign: |
| Inherent Redundancy in Spiking Neural Networks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.08227-b31b1b.svg)](https://arxiv.org/abs/2308.08227) | :heavy_minus_sign: |
| Achievement-based Training Progress Balancing for Multi-Task Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Prune Spatio-temporal Tokens by Semantic-aware Temporal Accumulation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.04549-b31b1b.svg)](https://arxiv.org/abs/2308.04549) | :heavy_minus_sign: |
| Differentiable Transportation Pruning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.08483-b31b1b.svg)](https://arxiv.org/abs/2307.08483) | :heavy_minus_sign: |
| XiNet: Efficient Neural Networks for tinyML | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Jumping through Local Minima: Quantization in the Loss Landscape of Vision Transformers | [![GitHub](https://img.shields.io/github/stars/enyac-group/evol-q)](https://github.com/enyac-group/evol-q) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10814-b31b1b.svg)](https://arxiv.org/abs/2308.10814) | :heavy_minus_sign: |
| A2Q: Accumulator-Aware Quantization with Guaranteed Overflow Avoidance | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.04383-b31b1b.svg)](https://arxiv.org/abs/2308.13504v1) | :heavy_minus_sign: |
| Workie-Talkie: Accelerating Federated Learning by Overlapping Computing and Communications via Contrastive Regularization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| DenseShift: Towards Accurate and Transferable Low-Bit Shift Network | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2208.09708-b31b1b.svg)](https://arxiv.org/abs/2208.09708) | :heavy_minus_sign: |
| PRANC: Pseudo RAndom Networks for Compacting deep models | [![GitHub](https://img.shields.io/github/stars/UCDvision/PRANC)](https://github.com/UCDvision/PRANC) | [![arXiv](https://img.shields.io/badge/arXiv-2206.08464-b31b1b.svg)](https://arxiv.org/abs/2206.08464) | :heavy_minus_sign: |
| Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness with Dataset Reinforcement | [![GitHub](https://img.shields.io/github/stars/apple/ml-dr)](https://github.com/apple/ml-dr) | [![arXiv](https://img.shields.io/badge/arXiv-2303.08983-b31b1b.svg)](https://arxiv.org/abs/2303.08983) | :heavy_minus_sign: |
| A Fast Unified System for 3D Object Detection and Tracking | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Estimator Meets Equilibrium Perspective: A Rectified Straight Through Estimator for Binary Neural Networks Training | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.06689-b31b1b.svg)](https://arxiv.org/abs/2308.06689) | :heavy_minus_sign: |
| I-ViT: Integer-only Quantization for Efficient Vision Transformer Inference | [![GitHub](https://img.shields.io/github/stars/zkkli/I-ViT)](https://github.com/zkkli/I-ViT) | [![arXiv](https://img.shields.io/badge/arXiv-2207.01405-b31b1b.svg)](https://arxiv.org/abs/2207.01405) | :heavy_minus_sign: |
| EMQ: Evolving Training-free Proxies for Automated Mixed Precision Quantization | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.10554-b31b1b.svg)](https://arxiv.org/abs/2307.10554) | :heavy_minus_sign: |
| Local or Global: Selective Knowledge Assimilation for Federated Learning with Limited Labels | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.08809-b31b1b.svg)](https://arxiv.org/abs/2307.08809) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Machine Learning (other than Deep Learning)

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Document Analysis and Understanding

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Biometrics

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Datasets and Evaluation

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Faces and Gestures

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Medical and Biological Vision; Cell Microscopy

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| BoMD: Bag of Multi-Label Local Descriptors for Noisy Chest X-Ray Classification | [![GitHub](https://img.shields.io/github/stars/cyh-0/BoMD)](https://github.com/cyh-0/BoMD) | [![arXiv](https://img.shields.io/badge/arXiv-2203.01937-b31b1b.svg)](https://arxiv.org/abs/2203.01937) | :heavy_minus_sign: |
| CLIP-Driven Universal Model for Organ Segmentation and Tumor Detection | [![GitHub](https://img.shields.io/github/stars/ljwztc/CLIP-Driven-Universal-Model)](https://github.com/ljwztc/CLIP-Driven-Universal-Model) | [![arXiv](https://img.shields.io/badge/arXiv-2301.00785-b31b1b.svg)](https://arxiv.org/abs/2301.00785) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Scene Analysis and Understanding

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Multimodal Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Human-in-the-Loop Computer Vision

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Image and Video Forensics

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Geometric Deep Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision Applications and Systems

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing | [![GitHub](https://img.shields.io/github/stars/aimagelab/multimodal-garment-designer)](https://github.com/aimagelab/multimodal-garment-designer) | [![arXiv](https://img.shields.io/badge/arXiv-2304.02051-b31b1b.svg)](https://arxiv.org/abs/2304.02051) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Machine Learning and Dataset

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Unmasked Teacher: Towards Training-Efficient Video Foundation Models | [![GitHub](https://img.shields.io/github/stars/OpenGVLab/unmasked_teacher)](https://github.com/OpenGVLab/unmasked_teacher) | [![arXiv](https://img.shields.io/badge/arXiv-2303.16058-b31b1b.svg)](https://arxiv.org/abs/2303.16058) | :heavy_minus_sign: |

---

## Star History

<p align="center">
    <a href="https://star-history.com/#Dmitryryumin/ICCV-2023-Papers&Date" target="_blank">
        <img width="500" src="https://api.star-history.com/svg?repos=Dmitryryumin/ICCV-2023-Papers&type=Date" alt="Star History Chart">
    </a>
<p>
