# ICCV-2023-Papers

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
![Version](https://img.shields.io/badge/version-v0.0.0-rc0)
![GitHub repo size](https://img.shields.io/github/repo-size/DmitryRyumin/ICCV-2023-Papers)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/LICENSE)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/README.md)
![GitHub contributors](https://img.shields.io/github/contributors/dmitryryumin/ICCV-2023-Papers)
![GitHub commit activity (branch)](https://img.shields.io/github/commit-activity/t/dmitryryumin/ICCV-2023-Papers)
![GitHub closed issues](https://img.shields.io/github/issues-closed/DmitryRyumin/ICCV-2023-Papers)
![GitHub issues](https://img.shields.io/github/issues/DmitryRyumin/ICCV-2023-Papers)
![GitHub closed pull requests](https://img.shields.io/github/issues-pr-closed/DmitryRyumin/ICCV-2023-Papers)
![GitHub pull requests](https://img.shields.io/github/issues-pr/dmitryryumin/ICCV-2023-Papers)
![GitHub last commit](https://img.shields.io/github/last-commit/DmitryRyumin/ICCV-2023-Papers)
![GitHub watchers](https://img.shields.io/github/watchers/dmitryryumin/ICCV-2023-Papers)
![GitHub forks](https://img.shields.io/github/forks/dmitryryumin/ICCV-2023-Papers)
![GitHub Repo stars](https://img.shields.io/github/stars/dmitryryumin/ICCV-2023-Papers)

---

ICCV 2023 Papers: Explore a comprehensive collection of cutting-edge research papers presented at [*ICCV 2023*](https://iccv2023.thecvf.com/), the premier computer vision conference. Keep up to date with the latest advances in computer vision and deep learning. Code implementations included. :star: the repository for the development of visual intelligence!

<p align="center">
    <a href="https://iccv2023.thecvf.com/" target="_blank">
        <img width="600" src="https://github.com/DmitryRyumin/ICCV-2023-Papers/blob/main/images/ICCV2023-banner.jpg" alt="ICCV 2023">
    </a>
<p>

---

[*The online version of the ICCV 2023 Conference Programme*](https://iccv2023.thecvf.com/main.conference.program-107.php), comprises a list of all accepted full papers, their presentation order, as well as the designated presentation times.

---

<a href="https://github.com/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arrow_click_cursor_pointer.png" width="25" />
  Other collections of the best AI conferences
</a>

<br />
<br />

> :exclamation: Conference table will be up to date all the time.

<table>
    <tr>
        <td><strong>Conference</strong></td>
        <td colspan="1" align="center"><strong>Year</strong></td>
    </tr>
    <tr>
      <td colspan="2" align="center"><i>Computer Vision (CV)</i></td>
    </tr>
    <tr>
        <td>CVPR</td>
        <td><a href="https://github.com/DmitryRyumin/CVPR-2023-Papers" target="_blank">2023</a></td>
    </tr>
    <tr>
      <td colspan="2" align="center"><i>Speech (SP)</i></td>
    </tr>
    <tr>
        <td>ICASSP</td>
        <td><a href="https://github.com/DmitryRyumin/ICASSP-2023-Papers" target="_blank">2023</a></td>
    </tr>
    <tr>
        <td>INTERSPEECH</td>
        <td><a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers" target="_blank">2023</a></td>
    </tr>
</table>

---

## Contributors

<a href="https://github.com/DmitryRyumin/ICCV-2023-Papers/graphs/contributors">
  <img src="http://contributors.nn.ci/api?repo=DmitryRyumin/ICCV-2023-Papers" />
</a>

<br />
<br />

Contributions to improve the completeness of this list are greatly appreciated. If you come across any overlooked papers, please **feel free to [*create pull requests*](https://github.com/DmitryRyumin/ICCV-2023-Papers/pulls), [*open issues*](https://github.com/DmitryRyumin/ICCV-2023-Papers/issues) or contact me via [*email*](mailto:neweraairesearch@gmail.com)**. Your participation is crucial to making this repository even better.

---

## [Papers](https://iccv2023.thecvf.com/main.conference.program-107.php)

> :exclamation: Final paper links will be added post-conference.

<details open>
<summary>List of sections<a id="sections"></a></summary>

- [3D from Multi-View and Sensors](#3d-from-multi-view-and-sensors)
- [Adversarial Attack and Defense](#adversarial-attack-and-defense)
- [Vision and Robotics](#vision-and-robotics)
- [Vision and Graphics](#vision-and-graphics)
- [Segmentation, Grouping and Shape Analysis](#segmentation-grouping-and-shape-analysis)
- [Recognition: Categorization](#recognition-categorization)
- [Explainable AI for CV](#explainable-ai-for-cv)
- [Neural Generative Models](#neural-generative-models)
- [Vision and Language](#vision-and-language)
- [Vision, Graphics, and Robotics](#vision-graphics-and-robotics)
- [Privacy, Security, Fairness, and Explainability](#privacy-security-fairness-and-explainability)
- [Fairness, Privacy, Ethics, Social-good, Transparency, Accountability in Vision](#fairness-privacy-ethics-social-good-transparency-accountability-in-vision)
- [First Person (Egocentric) Vision](#first-person-egocentric-vision)
- [Deep Learning Architectures](#deep-learning-architectures)
- [Recognition: Detection](#recognition-detection)
- [Image and Video Synthesis](#image-and-video-synthesis)
- [Vision and Audio](#vision-and-audio)
- [Recognition, Segmentation, and Shape Analysis](#recognition-segmentation-and-shape-analysis)
- [Generative AI](#generative-ai)
- [Humans, 3D Modeling, and Driving](#humans-3d-modeling-and-driving)
- [Low-Level Vision and Theory](#low-level-vision-and-theory)
- [Navigation and Autonomous Driving](#navigation-and-autonomous-driving)
- [3D from a Single Image and Shape-from-X](#3d-from-a-single-image-and-shape-from-x)
- [Motion Estimation, Matching and Tracking](#motion-estimation-matching-and-tracking)
- [Action and Event Understanding](#action-and-event-understanding)
- [Computational Imaging](#computational-imaging)
- [Embodied Vision: Active Agents; Simulation](#embodied-vision-active-agents-simulation)
- [Recognition: Retrieval](#recognition-retrieval)
- [Transfer, Low-Shot, Continual, Long-Tail Learning](#transfer-low-shot-continual-long-tail-learning)
- [Low-Level and Physics-based Vision](#low-level-and-physics-based-vision)
- [Computer Vision Theory](#computer-vision-theory)
- [Video Analysis and Understanding](#video-analysis-and-understanding)
- [Object Pose Estimation and Tracking](#object-pose-estimation-and-tracking)
- [3D Shape Modeling and Processing](#3d-shape-modeling-and-processing)
- [Human Pose/Shape Estimation](#human-poseshape-estimation)
- [Transfer, Low-Shot, and Continual Learning](#transfer-low-shot-and-continual-learning)
- [Self-, Semi-, and Unsupervised Learning](#self--semi--and-unsupervised-learning)
- [Self-, Semi-, Meta-, Unsupervised Learning](#self--semi--meta--unsupervised-learning)
- [Photogrammetry and Remote Sensing](#photogrammetry-and-remote-sensing)
- [Efficient and Scalable Vision](#efficient-and-scalable-vision)
- [Machine Learning (other than Deep Learning)](#machine-learning-other-than-deep-learning)
- [Document Analysis and Understanding](#document-analysis-and-understanding)
- [Biometrics](#biometrics)
- [Datasets and Evaluation](#datasets-and-evaluation)
- [Faces and Gestures](#faces-and-gestures)
- [Medical and Biological Vision; Cell Microscopy](#medical-and-biological-vision-cell-microscopy)
- [Scene Analysis and Understanding](#scene-analysis-and-understanding)
- [Multimodal Learning](#multimodal-learning)
- [Human-in-the-Loop Computer Vision](#human-in-the-loop-computer-vision)
- [Image and Video Forensics](#image-and-video-forensics)
- [Geometric Deep Learning](#geometric-deep-learning)
- [Vision Applications and Systems](#vision-applications-and-systems)
- [Machine Learning and Dataset](#machine-learning-and-dataset)

</details>

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### 3D from Multi-View and Sensors

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Multi-Modal Neural Radiance Field for Monocular Dense SLAM with a Light-Weight ToF Sensor | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.14383-b31b1b.svg)](https://arxiv.org/abs/2308.14383) | :heavy_minus_sign: |
| ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cy94.github.io/scannetpp/) | [![arXiv](https://img.shields.io/badge/arXiv-2308.11417-b31b1b.svg)](https://arxiv.org/abs/2308.11417) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=E6P9e2r6M8I) |
| Translating Images to Road Network: A Non-Autoregressive Sequence-to-Sequence Approach | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Doppelgangers: Learning to Disambiguate Images of Similar Structures | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://doppelgangers-3d.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/RuojinCai/Doppelgangers)](https://github.com/RuojinCai/Doppelgangers) | :heavy_minus_sign: | :heavy_minus_sign: |
| EgoLoc: Revisiting 3D Object Localization from Egocentric Videos with Visual Queries | [![GitHub](https://img.shields.io/github/stars/Wayne-Mai/EgoLoc)](https://github.com/Wayne-Mai/EgoLoc) | [![arXiv](https://img.shields.io/badge/arXiv-2212.06969-b31b1b.svg)](https://arxiv.org/abs/2212.06969) | :heavy_minus_sign: |
| ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via an Indirect Recording Solution | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| EMR-MSF: Self-Supervised Recurrent Monocular Scene Flow Exploiting Ego-Motion Rigidity | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| ENVIDR: Implicit Differentiable Renderer with Neural Environment Lighting | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nexuslrf.github.io/ENVIDR/) <br /> [![GitHub](https://img.shields.io/github/stars/nexuslrf/ENVIDR)](https://github.com/nexuslrf/ENVIDR) | [![arXiv](https://img.shields.io/badge/arXiv-2303.13022-b31b1b.svg)](https://arxiv.org/abs/2303.13022) | [![Google Drive](https://img.shields.io/badge/Google%20Drive-4285F4?style=for-the-badge&logo=googledrive&logoColor=white)](https://drive.google.com/file/d/18kU-IWVxboCG8SCGgrBA5JHC0JIgPCS8/view?t=17s) |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Adversarial Attack and Defense

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Robust Mixture-of-Expert Training for Convolutional Neural Networks | [![GitHub](https://img.shields.io/github/stars/OPTML-Group/Robust-MoE-CNN)](https://github.com/OPTML-Group/Robust-MoE-CNN) | [![arXiv](https://img.shields.io/badge/arXiv-2308.10110-b31b1b.svg)](https://arxiv.org/abs/2308.10110) | :heavy_minus_sign: |
| Set-Level Guidance Attack: Boosting Adversarial Transferability of Vision-Language Pre-Training Models | [![GitHub](https://img.shields.io/github/stars/Zoky-2020/SGA)](https://github.com/Zoky-2020/SGA) | [![arXiv](https://img.shields.io/badge/arXiv-2307.14061-b31b1b.svg)](https://arxiv.org/abs/2307.14061) | :heavy_minus_sign: |
| CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning | [![GitHub](https://img.shields.io/github/stars/nishadsinghi/CleanCLIP)](https://github.com/nishadsinghi/CleanCLIP) | [![arXiv](https://img.shields.io/badge/arXiv-2303.03323-b31b1b.svg)](https://arxiv.org/abs/2303.03323) | :heavy_minus_sign: |
| CGBA: Curvature-Aware Geometric Black-Box Attack | [![GitHub](https://img.shields.io/github/stars/Farhamdur/CGBA)](https://github.com/Farhamdur/CGBA) | [![arXiv](https://img.shields.io/badge/arXiv-2308.03163-b31b1b.svg)](https://arxiv.org/abs/2308.03163) | :heavy_minus_sign: |
| Robust Evaluation of Diffusion-based Adversarial Purification |  |  |  |
| Advancing Example Exploitation can Alleviate Critical Challenges in Adversarial Training |  |  |  |
| The Victim and the Beneficiary: Exploiting a Poisoned Model to Train a Clean Model on Poisoned Data |  |  |  |
| TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal Backdoored Models |  |  |  |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision and Robotics

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision and Graphics

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Segmentation, Grouping and Shape Analysis

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Recognition: Categorization

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Explainable AI for CV

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Neural Generative Models

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision and Language

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision, Graphics, and Robotics

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Privacy, Security, Fairness, and Explainability

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Fairness, Privacy, Ethics, Social-good, Transparency, Accountability in Vision

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### First Person (Egocentric) Vision

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Deep Learning Architectures

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Recognition: Detection

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Image and Video Synthesis

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision and Audio

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Recognition, Segmentation, and Shape Analysis

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Generative AI

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Humans, 3D Modeling, and Driving

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Low-Level Vision and Theory

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Navigation and Autonomous Driving

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### 3D from a Single Image and Shape-from-X

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Motion Estimation, Matching and Tracking

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Action and Event Understanding

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Computational Imaging

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Embodied Vision: Active Agents; Simulation

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Recognition: Retrieval

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Transfer, Low-Shot, Continual, Long-Tail Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Low-Level and Physics-based Vision

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Computer Vision Theory

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Video Analysis and Understanding

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Object Pose Estimation and Tracking

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### 3D Shape Modeling and Processing

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Human Pose/Shape Estimation

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Transfer, Low-Shot, and Continual Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Self-, Semi-, and Unsupervised Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Self-, Semi-, Meta-, Unsupervised Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Photogrammetry and Remote Sensing

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Efficient and Scalable Vision

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Machine Learning (other than Deep Learning)

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Document Analysis and Understanding

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Biometrics

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Datasets and Evaluation

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Faces and Gestures

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Medical and Biological Vision; Cell Microscopy

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Scene Analysis and Understanding

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Multimodal Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Human-in-the-Loop Computer Vision

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Image and Video Forensics

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Geometric Deep Learning

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Vision Applications and Systems

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Machine Learning and Dataset

> Will soon be added
